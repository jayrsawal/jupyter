{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import sqlalchemy\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import pickle\n",
    "import joblib\n",
    "import PyPDF2\n",
    "import docx\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "connstr = \"\"\n",
    "engine = sqlalchemy.create_engine(connstr)\n",
    "# toefl = pd.read_sql(\"select id, convert(content using utf8) content from toefl\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_hash = {}\n",
    "dupes = {}\n",
    "empty = {}\n",
    "notfound = {}\n",
    "directory = \"../data/Buffer2/\"\n",
    "for filename in os.listdir(directory):\n",
    "    with open(directory+filename, \"r+\",encoding='utf-8') as f:\n",
    "        data = f.read().encode(\"utf-8\")\n",
    "        key = hashlib.md5(data).hexdigest()\n",
    "        clean_name = filename.replace(\".json\",\"\")\n",
    "        if key in file_hash:\n",
    "            j = json.loads(data)\n",
    "            matches = j[\"matches\"]\n",
    "            if len(matches) > 0:\n",
    "                orig = toefl[toefl[\"content\"].str.match(matches[0][\"sentence\"])]\n",
    "                if orig.shape[0] > 0:\n",
    "                    dupes[clean_name] = orig[\"id\"].values[0]\n",
    "                else:\n",
    "                    notfound[key] = clean_name\n",
    "            else:\n",
    "                empty[key] = clean_name\n",
    "        else:\n",
    "            file_hash[key] = clean_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dupes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(notfound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n"
     ]
    }
   ],
   "source": [
    "API_ENDPOINT = \"http://localhost:8081/v2/check\"\n",
    "for index, row in toefl.iterrows():\n",
    "    id = str(row[\"id\"]) + \".json\"\n",
    "    data = { \"language\": \"en-US\", \"text\": row[\"content\"] }\n",
    "    r = requests.post(url = API_ENDPOINT, data = data)\n",
    "    with open('../data/Buffer2/' + id, 'w+') as outfile:  \n",
    "        json.dump(r.text, outfile)\n",
    "    if index % 1000 == 0:\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "db = engine.connect()\n",
    "count = dict()\n",
    "for fn in os.listdir('../data/Buffer2'):\n",
    "    file_id = fn.strip('.json')\n",
    "    with open('../data/Buffer2/' + fn, 'r') as f:\n",
    "        data = json.loads(f.read())\n",
    "        vals = json.loads(data)\n",
    "        count[file_id] = len(vals['matches'])\n",
    "        for m in vals['matches']:\n",
    "            message = m['message']\n",
    "            short_message = m['shortMessage']\n",
    "            offset = m['offset']\n",
    "            length = m['length']\n",
    "            context_text = m['context']['text']\n",
    "            context_offset = m['context']['offset']\n",
    "            context_length = m['context']['length']\n",
    "            sentence = m['sentence']\n",
    "            rule_name = m['rule']['id']\n",
    "            rule_description = m['rule']['description']\n",
    "            rule_issue = m['rule']['issueType']\n",
    "            essay_set = 1\n",
    "            category_name = m['rule']['category']['id']\n",
    "\n",
    "            fetch = db.execute('SELECT id from error_rule where text_id = \"' + rule_name + '\";')\n",
    "            res = fetch.fetchone()\n",
    "            if not res:\n",
    "                fetch = db.execute('SELECT id from error_category where text_id = \"' + category_name + '\";')\n",
    "                res = fetch.fetchone()\n",
    "                cat_id = res[0]\n",
    "                db.execute('INSERT INTO error_rule(text_id, description, issue_type, category_id) VALUES(%s, %s, %s, %s);', (rule_name, rule_description, rule_issue, cat_id))\n",
    "                fetch = db.execute(\"select last_insert_id();\")\n",
    "                rule_id = fetch.fetchone()[0]\n",
    "            else:\n",
    "                rule_id = res[0]\n",
    "            db.execute('INSERT INTO error_matches(message, short_message, offset, length, context_text, context_offset, context_length, sentence, rule_id, file_id, essay_set) VALUES(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s, %s);', (message, short_message, offset, length, context_text, context_offset, context_length, sentence, rule_id, file_id, essay_set))\n",
    "            \n",
    "for k in count.keys():\n",
    "    fetch = db.execute('select count(id) from error_matches where file_id = ' + k + ' and essay_set = 1;')\n",
    "    v = fetch.fetchone()\n",
    "    if v[0] != count[k]:\n",
    "        print(k, v[0], count[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_zipped_pickle(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        loaded_object = pickle.load(f)\n",
    "        return loaded_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "file must have 'read' and 'readline' attributes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-5f1dbe406972>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/vectorizer.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mcount_vect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/tfidf.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: file must have 'read' and 'readline' attributes"
     ]
    }
   ],
   "source": [
    "count_vect = None\n",
    "tfidf = None\n",
    "with open(\"../data/vectorizer.pkl\",\"rb\") as f:\n",
    "    count_vect = pickle.load(f)\n",
    "with open(\"../data/tfidf.pkl\",\"rb\") as f:\n",
    "    tfidf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ageneralreinforcementlearningalgorithmthat\\nmasterschess,shogiandGothroughself-play\\nDavidSilver,\\n1\\n;\\n2\\n\\nThomasHubert,\\n1\\n\\nJulianSchrittwieser,\\n1\\n\\nIoannisAntonoglou,\\n1\\n;\\n2\\nMatthewLai,\\n1\\nArthurGuez,\\n1\\nMarcLanctot,\\n1\\nLaurentSifre,\\n1\\nDharshanKumaran,\\n1\\n;\\n2\\nThoreGraepel,\\n1\\n;\\n2\\nTimothyLillicrap,\\n1\\nKarenSimonyan,\\n1\\nDemisHassabis\\n1\\n1\\nDeepMind,6PancrasSquare,LondonN1C4AG.\\n2\\nUniversityCollegeLondon,GowerStreet,LondonWC1E6BT.\\n\\nTheseauthorscontributedequallytothiswork.\\nAbstract\\nThegameofchessisthelongest-studieddomaininthehistoryofintelligence.\\nThestrongestprogramsarebasedonacombinationofsophisticatedsearchtechniques,\\nadaptations,andhandcraftedevaluationfunctionsthathavebeen\\nbyhumanexpertsoverseveraldecades.Bycontrast,theAlphaGoZeroprogramrecently\\nachievedsuperhumanperformanceinthegameofGobyreinforcementlearningfromself-\\nplay.Inthispaper,wegeneralizethisapproachintoasingleAlphaZeroalgorithmthatcan\\nachievesuperhumanperformanceinmanychallenginggames.Startingfromrandomplay\\nandgivennodomainknowledgeexceptthegamerules,AlphaZeroconvincinglydefeated\\naworldchampionprograminthegamesofchessandshogi(Japanesechess)aswellasGo.\\nThestudyofcomputerchessisasoldascomputerscienceitself.CharlesBabbage,Alan\\nTuring,ClaudeShannon,andJohnvonNeumanndevisedhardware,algorithmsandtheoryto\\nanalyseandplaythegameofchess.Chesssubsequentlybecameagrandchallengetaskfor\\nagenerationofintelligenceresearchers,culminatinginhigh-performancecomputer\\nchessprogramsthatplayatasuper-humanlevel(\\n1,2\\n).However,thesesystemsarehighlytuned\\ntotheirdomain,andcannotbegeneralizedtoothergameswithoutsubstantialhumaneffort,\\nwhereasgeneralgame-playingsystems(\\n3,4\\n)remaincomparativelyweak.\\nAlong-standingambitionofintelligencehasbeentocreateprogramsthatcanin-\\nsteadlearnforthemselvesfromprinciples(\\n5,6\\n).Recently,theAlphaGoZeroalgorithm\\nachievedsuperhumanperformanceinthegameofGo,byrepresentingGoknowledgeusing\\ndeepconvolutionalneuralnetworks(\\n7,8\\n),trainedsolelybyreinforcementlearningfromgames\\n1\\n', 'ofself-play(\\n9\\n).Inthispaper,weintroduceAlphaZero:amoregenericversionoftheAlphaGo\\nZeroalgorithmthataccomodates,withoutspecial-casing,toabroaderclassofgamerules.We\\napplyAlphaZerotothegamesofchessandshogiaswellasGo,usingthesamealgorithmand\\nnetworkarchitectureforallthreegames.Ourresultsdemonstratethatageneral-purposerein-\\nforcementlearningalgorithmcanlearn,tabularasaŒwithouthumanknowl-\\nedgeordata,asevidencedbythesamealgorithmsucceedinginmultipledomainsŒsuperhuman\\nperformanceacrossmultiplechallenginggames.\\nAlandmarkforintelligencewasachievedin1997whenDeepBluedefeatedthe\\nhumanworldchesschampion(\\n1\\n).Computerchessprogramscontinuedtoprogresssteadily\\nbeyondhumanlevelinthefollowingtwodecades.Theseprogramsevaluatepositionsusing\\nhandcraftedfeaturesandcarefullytunedweights,constructedbystronghumanplayersand\\nprogrammers,combinedwithahigh-performancealpha-betasearchthatexpandsavastsearch\\ntreeusingalargenumberofcleverheuristicsandadaptations.In(\\n10\\n)we\\ndescribetheseaugmentations,focusingonthe2016TopChessEngineChampionship(TCEC)\\nseason9world-champion(\\n11\\n);otherstrongchessprograms,includingDeepBlue,\\nuseverysimilararchitectures(\\n1,12\\n).\\nIntermsofgametreecomplexity,shogiisasubstantiallyhardergamethanchess(\\n13,14\\n):\\nitisplayedonalargerboardwithawidervarietyofpieces;anycapturedopponentpiece\\nswitchessidesandmaysubsequentlybedroppedanywhereontheboard.Thestrongestshogi\\nprograms,suchasthe2017ComputerShogiAssociation(CSA)world-championElmo,have\\nonlyrecentlydefeatedhumanchampions(\\n15\\n).Theseprogramsuseanalgorithmsimilarto\\nthoseusedbycomputerchessprograms,againbasedonahighlyoptimizedalpha-betasearch\\nenginewithmanyadaptations.\\nAlphaZeroreplacesthehandcraftedknowledgeanddomain-spaugmentationsusedin\\ntraditionalgame-playingprogramswithdeepneuralnetworks,ageneral-purposereinforcement\\nlearningalgorithm,andageneral-purposetreesearchalgorithm.\\nInsteadofahandcraftedevaluationfunctionandmoveorderingheuristics,AlphaZerouses\\nadeepneuralnetwork\\n(\\np\\n;v\\n)=\\nf\\n\\n(\\ns\\n)\\nwithparameters\\n\\n.Thisneuralnetwork\\nf\\n\\n(\\ns\\n)\\ntakesthe\\nboardposition\\ns\\nasaninputandoutputsavectorofmoveprobabilities\\np\\nwithcomponents\\np\\na\\n=Pr(\\na\\nj\\ns\\n)\\nforeachaction\\na\\n,andascalarvalue\\nv\\nestimatingtheexpectedoutcome\\nz\\nof\\nthegamefromposition\\ns\\n,\\nv\\nˇ\\nE\\n[\\nz\\nj\\ns\\n]\\n.AlphaZerolearnsthesemoveprobabilitiesandvalue\\nestimatesentirelyfromself-play;thesearethenusedtoguideitssearchinfuturegames.\\nInsteadofanalpha-betasearchwithenhancements,AlphaZerousesageneral-\\npurposeMonteCarlotreesearch(MCTS)algorithm.Eachsearchconsistsofaseriesofsim-\\nulatedgamesofself-playthattraverseatreefromrootstate\\ns\\nroot\\nuntilaleafstateisreached.\\nEachsimulationproceedsbyselectingineachstate\\ns\\namove\\na\\nwithlowvisitcount(notprevi-\\nouslyfrequentlyexplored),highmoveprobabilityandhighvalue(averagedovertheleafstates\\nofsimulationsthatselected\\na\\nfrom\\ns\\n)accordingtothecurrentneuralnetwork\\nf\\n\\n.Thesearch\\nreturnsavector\\nˇ\\nˇ\\nˇ\\nrepresentingaprobabilitydistributionovermoves,\\nˇ\\na\\n=Pr(\\na\\nj\\ns\\nroot\\n)\\n.\\nTheparameters\\n\\nofthedeepneuralnetworkinAlphaZeroaretrainedbyreinforcement\\nlearningfromself-playgames,startingfromrandomlyinitializedparameters\\n\\n.Eachgameis\\n2\\n', 'playedbyrunninganMCTSsearchfromthecurrentposition\\ns\\nroot\\n=\\ns\\nt\\natturn\\nt\\n,andthen\\nselectingamove,\\na\\nt\\n˘\\nˇ\\nˇ\\nˇ\\nt\\n,eitherproportionally(forexploration)orgreedily(forexploitation)\\nwithrespecttothevisitcountsattherootstate.Attheendofthegame,theterminalposition\\ns\\nT\\nisscoredaccordingtotherulesofthegametocomputethegameoutcome\\nz\\n:\\n\\n1\\nforaloss,\\n0\\nforadraw,and\\n+1\\nforawin.Theneuralnetworkparameters\\n\\nareupdatedtominimizethe\\nerrorbetweenthepredictedoutcome\\nv\\nt\\nandthegameoutcome\\nz\\n,andtomaximizethesimilarity\\nofthepolicyvector\\np\\nt\\ntothesearchprobabilities\\nˇ\\nˇ\\nˇ\\nt\\n.,theparameters\\n\\nareadjusted\\nbygradientdescentonalossfunction\\nl\\nthatsumsovermean-squarederrorandcross-entropy\\nlosses,\\n(\\np\\n;v\\n)=\\nf\\n\\n(\\ns\\n)\\n;l\\n=(\\nz\\n\\nv\\n)\\n2\\n\\nˇ\\nˇ\\nˇ\\n>\\nlog\\np\\n+\\nc\\njj\\n\\njj\\n2\\n;\\n(1)\\nwhere\\nc\\nisaparametercontrollingthelevelof\\nL\\n2\\nweightregularization.Theupdatedparameters\\nareusedinsubsequentgamesofself-play.\\nTheAlphaZeroalgorithmdescribedinthispaper(see(\\n10\\n)forpseudocode)differsfromthe\\noriginalAlphaGoZeroalgorithminseveralrespects.\\nAlphaGoZeroestimatedandoptimizedtheprobabilityofwinning,exploitingthefactthat\\nGogameshaveabinarywinorlossoutcome.However,bothchessandshogimayendindrawn\\noutcomes;itisbelievedthattheoptimalsolutiontochessisadraw(\\n16Œ18\\n).AlphaZeroinstead\\nestimatesandoptimizestheexpectedoutcome.\\nTherulesofGoareinvarianttorotationandThisfactwasexploitedin\\nAlphaGo\\nandAlphaGoZerointwoways.First,trainingdatawereaugmentedbygeneratingeightsym-\\nmetriesforeachposition.Second,duringMCTS,boardpositionsweretransformedbyusinga\\nrandomlyselectedrotationorbeforebeingevaluatedbytheneuralnetwork,sothat\\ntheMonteCarloevaluationwasaveragedoverdifferentbiases.Toaccommodateabroaderclass\\nofgames,AlphaZerodoesnotassumesymmetry;therulesofchessandshogiareasymmetric\\n(e.g.pawnsonlymoveforward,andcastlingisdifferentonkingsideandqueenside).AlphaZero\\ndoesnotaugmentthetrainingdataanddoesnottransformtheboardpositionduringMCTS.\\nInAlphaGoZero,self-playgamesweregeneratedbythebestplayerfromallpreviousitera-\\ntions.Aftereachiterationoftraining,theperformanceofthenewplayerwasmeasuredagainst\\nthebestplayer;ifthenewplayerwonbyamarginof\\n55%\\nthenitreplacedthebestplayer.By\\ncontrast,AlphaZerosimplymaintainsasingleneuralnetworkthatisupdatedcontinually,rather\\nthanwaitingforaniterationtocomplete.Self-playgamesarealwaysgeneratedbyusingthe\\nlatestparametersforthisneuralnetwork.\\nLikeAlphaGoZero,theboardstateisencodedbyspatialplanesbasedonlyonthebasic\\nrulesforeachgame.Theactionsareencodedbyeitherspatialplanesoravector,again\\nbasedonlyonthebasicrulesforeachgame(\\n10\\n).\\nAlphaGoZerousedaconvolutionalneuralnetworkarchitecturethatisparticularlywell-\\nsuitedtoGo:therulesofthegamearetranslationallyinvariant(matchingtheweightsharing\\nstructureofconvolutionalnetworks)andareintermsoflibertiescorrespondingtothe\\nadjacenciesbetweenpointsontheboard(matchingthelocalstructureofconvolutionalnet-\\nworks).Bycontrast,therulesofchessandshogiareposition-dependent(e.g.pawnsmay\\n3\\n', \"Figure1:\\nTrainingAlphaZerofor700,000steps.\\nEloratingswerecomputedfromgames\\nbetweendifferentplayerswhereeachplayerwasgivenonesecondpermove.\\n(A)\\nPerformance\\nofAlphaZeroinchess,comparedwiththe2016TCECworld-championprogram\\n(B)\\nPerformanceofAlphaZeroinshogi,comparedwiththe2017CSAworld-championprogram\\nElmo.\\n(C)\\nPerformanceofAlphaZeroinGo,comparedwithAlphaGoLeeandAlphaGoZero\\n(20blocksover3days).\\nmovetwostepsforwardfromthesecondrankandpromoteontheeighthrank)andinclude\\nlong-rangeinteractions(e.g.thequeenmaytraversetheboardinonemove).Despitethese\\ndifferences,AlphaZerousesthesameconvolutionalnetworkarchitectureasAlphaGoZerofor\\nchess,shogiandGo.\\nThehyperparametersofAlphaGoZeroweretunedbyBayesianoptimization.InAlphaZero\\nwereusethesamehyperparameters,algorithmsettingsandnetworkarchitectureforallgames\\nwithoutgtuning.Theonlyexceptionsaretheexplorationnoiseandthelearning\\nrateschedule(see(\\n10\\n)forfurtherdetails).\\nWetrainedseparateinstancesofAlphaZeroforchess,shogiandGo.Trainingproceededfor\\n700,000steps(inmini-batchesof4,096trainingpositions)startingfromrandomlyinitialized\\nparameters.Duringtrainingonly,5,000tensorprocessingunits(TPUs)(\\n19\\n)\\nwereusedtogenerateself-playgames,and16second-generationTPUswereusedtotrainthe\\nneuralnetworks.Traininglastedforapproximately9hoursinchess,12hoursinshogiand13\\ndaysinGo(seetableS3)(\\n20\\n).Furtherdetailsofthetrainingprocedureareprovidedin(\\n10\\n).\\nFigure1showstheperformanceofAlphaZeroduringself-playreinforcementlearning,as\\nafunctionoftrainingsteps,onanElo(\\n21\\n)scale(\\n22\\n).Inchess,AlphaZerooutperformed\\nafterjust4hours(300,000steps);inshogi,AlphaZerooutperformedElmoafter\\n2hours(110,000steps);andinGo,AlphaZerooutperformedAlphaGoLee(\\n9\\n)after30\\nhours(74,000steps).Thetrainingalgorithmachievedsimilarperformanceinallindependent\\nruns(seeS3),suggestingthatthehighperformanceofAlphaZero'strainingalgorithmis\\nrepeatable.\\nWeevaluatedthefullytrainedinstancesofAlphaZeroagainstElmoandthepre-\\nviousversionofAlphaGoZeroinchess,shogiandGorespectively.Eachprogramwasrunon\\nthehardwareforwhichitwasdesigned(\\n23\\n):andElmoused44centralprocessing\\nunit(CPU)cores(asintheTCECworldchampionship),whereasAlphaZeroandAlphaGoZero\\nusedasinglemachinewithfourTPUsand44CPUcores(\\n24\\n).Thechessmatch\\n4\\n\", 'wasplayedagainstthe2016TCEC(season9)worldchampion(see(\\n10\\n)fordetails).\\nTheshogimatchwasplayedagainstthe2017CSAworldchampionversionofElmo(\\n10\\n).The\\nGomatchwasplayedagainstthepreviouslypublishedversionofAlphaGoZero(alsotrained\\nfor700,000steps(\\n25\\n)).Allmatcheswereplayedusingtimecontrolsof3hourspergame,plus\\nanadditional15secondsforeachmove.\\nInGo,AlphaZerodefeatedAlphaGoZero(\\n9\\n),winning61%ofgames.Thisdemonstrates\\nthatageneralapproachcanrecovertheperformanceofanalgorithmthatexploitedboardsym-\\nmetriestogenerateeighttimesasmuchdata(seealsoS1).\\nInchess,AlphaZerodefeatedwinning155gamesandlosing6gamesoutof1,000\\n(Fig.2).ToverifytherobustnessofAlphaZero,weplayedadditionalmatchesthatstartedfrom\\ncommonhumanopenings(Fig.3).AlphaZerodefeatedineachopening,suggesting\\nthatAlphaZerohasmasteredawidespectrumofchessplay.ThefrequencyplotsinFig.3and\\nthetimelineinS2showthatcommonhumanopeningswereindependentlydiscoveredand\\nplayedfrequentlybyAlphaZeroduringself-playtraining.Wealsoplayedamatchthatstarted\\nfromthesetofopeningpositionsusedinthe2016TCECworldchampionship;AlphaZerowon\\nconvincinglyinthismatchtoo(\\n26\\n)(seeS4).Weplayedadditionalmatchesagainstthe\\nmostrecentdevelopmentversionof(\\n27\\n),andavariantofthatusesastrong\\nopeningbook(\\n28\\n).AlphaZerowonallmatchesbyalargemargin(Fig.2).\\nTableS6shows20chessgamesplayedbyAlphaZeroinitsmatchesagainstIn\\nseveralgamesAlphaZeropiecesforlong-termstrategicadvantage,suggestingthatit\\nhasamorecontext-dependentpositionalevaluationthantherule-basedevaluationsused\\nbypreviouschessprograms.\\nInshogi,AlphaZerodefeatedElmo,winning98.2%ofgameswhenplayingblack,and\\n91.2%overall.Wealsoplayedamatchunderthefastertimecontrolsusedinthe2017CSA\\nworldchampionship,andagainstanotherstate-of-the-artshogiprogram(\\n29\\n);AlphaZeroagain\\nwonbothmatchesbyawidemargin(Fig.2).\\nTableS7shows10shogigamesplayedbyAlphaZeroinitsmatchesagainstElmo.The\\nfrequencyplotsinFig.3andthetimelineinS2showthatAlphaZerofrequentlyplaysone\\nofthetwomostcommonhumanopenings,butrarelyplaysthesecond,deviatingonthevery\\nmove.\\nAlphaZerosearchesjust60,000positionspersecondinchessandshogi,comparedwith60\\nmillionforand25millionforElmo(tableS4).AlphaZeromaycompensateforthe\\nlowernumberofevaluationsbyusingitsdeepneuralnetworktofocusmuchmoreselectively\\nonthemostpromisingvariations(Fig.4providesanexamplefromthematchagainst\\nŒarguablyamoreﬁhuman-likeﬂapproachtosearch,asoriginallyproposedbyShannon(\\n30\\n).\\nAlphaZeroalsodefeatedwhengiven\\n1\\n=\\n10\\nasmuchthinkingtimeasitsopponent\\n(i.e.searching~\\n1\\n=\\n10\\n;\\n000\\nasmanypositions),andwon46%ofgamesagainstElmowhen\\ngiven\\n1\\n=\\n100\\nasmuchtime(i.e.searching~\\n1\\n=\\n40\\n;\\n000\\nasmanypositions),seeFig.2.Thehigh\\nperformanceofAlphaZero,usingMCTS,callsintoquestionthewidelyheldbelief(\\n31,32\\n)that\\nalpha-betasearchisinherentlysuperiorinthesedomains.\\nThegameofchessrepresentedthepinnacleofintelligenceresearchoverseveral\\n5\\n', 'decades.State-of-the-artprogramsarebasedonpowerfulenginesthatsearchmanymillions\\nofpositions,leveraginghandcrafteddomainexpertiseandsophisticateddomainadaptations.\\nAlphaZeroisagenericreinforcementlearningandsearchalgorithmŒoriginallydevisedforthe\\ngameofGoŒthatachievedsuperiorresultswithinafewhours,searching\\n1\\n=\\n1\\n;\\n000\\nasmanypo-\\nsitions,givennodomainknowledgeexcepttherulesofchess.Furthermore,thesamealgorithm\\nwasappliedwithouttothemorechallenginggameofshogi,againoutperforming\\nstate-of-the-artprogramswithinafewhours.Theseresultsbringusastepcloserto\\nalongstandingambitionofintelligence(\\n3\\n):ageneralgamesplayingsystemthatcan\\nlearntomasteranygame.\\nReferences\\n1.\\nM.Campbell,A.J.Hoane,F.Hsu,\\nIntelligence\\n134\\n,57(2002).\\n2.\\nF.-h.Hsu,\\nBehindDeepBlue:BuildingtheComputerthatDefeatedtheWorldChessCham-\\npion\\n(PrincetonUniversityPress,2002).\\n3.\\nB.Pell,\\nComputationalIntelligence\\n12\\n,177(1996).\\n4.\\nM.R.Genesereth,N.Love,B.Pell,\\nAIMagazine\\n26\\n,62(2005).\\n5.\\nA.L.Samuel,\\nIBMJournalofResearchandDevelopment\\n11\\n,601(1967).\\n6.\\nG.Tesauro,\\nNeuralComputation\\n6\\n,215(1994).\\n7.\\nC.J.Maddison,A.Huang,I.Sutskever,D.Silver,\\nInternationalConferenceonLearning\\nRepresentations\\n(2015).\\n8.\\nD.Silver,\\netal.\\n,\\nNature\\n529\\n,484(2016).\\n9.\\nD.Silver,\\netal.\\n,\\nNature\\n550\\n,354(2017).\\n10.\\nSeethesupplementarymaterialsforadditionalinformation.\\n11.\\nT.Romstad,M.Costalba,J.Kiiski,\\netal.\\n,Astrongopensourcechessengine.\\nhttps://stockfishchess.org/\\n.RetrievedNovember29th,2017.\\n12.\\nD.N.L.Levy,M.Newborn,\\nHowComputersPlayChess\\n(IshiPress,2009).\\n13.\\nV.Allis,Searchingforsolutionsingamesandintelligence,Ph.D.thesis,University\\nofLimburg,Netherlands(1994).\\n14.\\nH.Iida,M.Sakuta,J.Rollason,\\nIntelligence\\n134\\n,121(2002).\\n6\\n', \"Figure2:\\nComparisonwithspecializedprograms.(A)\\nTournamentevaluationofAlphaZero\\ninchess,shogi,andGoinmatchesagainstrespectivelyElmo,andthepreviouslypub-\\nlishedversionofAlphaGoZero(AG0)thatwastrainedfor3days.Inthetopbar,AlphaZero\\nplayswhite;inthebottombarAlphaZeroplaysblack.Eachbarshowstheresultsfrom\\nAlphaZero'sperspective:win(`W',green),draw(`D',grey),loss(`L',red).\\n(B)\\nScalability\\nofAlphaZerowiththinkingtime,comparedtohandElmo.andElmoalways\\nreceivefulltime(3hourspergameplus15secondspermove),timeforAlphaZeroisscaled\\ndownasindicated.\\n(C)\\nExtraevaluationsofAlphaZeroinchessagainstthemostrecentversion\\nofatthetimeofwriting(\\n27\\n),andagainstwithastrongopeningbook(\\n28\\n).\\nExtraevaluationsofAlphaZeroinshogiwerecarriedoutagainstanotherstrongshogiprogram\\nAperyqhapaq(\\n29\\n)atfulltimecontrolsandagainstElmounder2017CSAworldchampionship\\ntimecontrols(10minutespergameplus10secondspermove).\\n(D)\\nAverageresultofchess\\nmatchesstartingfromdifferentopeningpositions:eithercommonhumanpositions(seealso\\nFig.3),orthe2016TCECworldchampionshipopeningpositions(seealsoS4).Average\\nresultofshogimatchesstartingfromcommonhumanpositions(seealsoFig.3).CSAworld\\nchampionshipgamesstartfromtheinitialboardposition.\\nMatchconditionsaresummarizedintablesS8andS9.\\n7\\n\", \"Figure3:\\nMatchesstartingfromthemostpopularhumanopenings\\n.AlphaZeroplays\\nagainst\\n(A)\\ninchessand\\n(B)\\nElmoinshogi.Intheleftbar,AlphaZeroplayswhite,\\nstartingfromthegivenposition;intherightbarAlphaZeroplaysblack.Eachbarshowsthe\\nresultsfromAlphaZero'sperspective:win(green),draw(grey),loss(red).Thepercentagefre-\\nquencyofself-playtraininggamesinwhichthisopeningwasselectedbyAlphaZeroisplotted\\nagainstthedurationoftraining,inhours.\\n8\\n\", \"Figure4:\\nAlphaZero'ssearchprocedure.\\nThesearchisillustratedforaposition(inset)\\nfromgame1(tableS6)betweenAlphaZero(white)and(black)after29....Qf8.\\nTheinternalstateofAlphaZero'sMCTSissummarizedafter\\n10\\n2\\n;:::;\\n10\\n6\\nsimulations.Each\\nsummaryshowsthe10mostvisitedstates.Theestimatedvalueisshownineachstate,from\\nwhite'sperspective,scaledtotherange\\n[0\\n;\\n100]\\n.Thevisitcountofeachstate,relativetothe\\nrootstateofthattree,isproportionaltothethicknessofthebordercircle.AlphaZeroconsiders\\n30.c6buteventuallyplays30.d5.\\n9\\n\", \"15.\\nC.S.Association,Resultsofthe27thworldcomputershogichampionship.\\nhttp:\\n//www2.computer-shogi.org/wcsc27/index_e.html\\n.RetrievedNovember\\n29th,2017.\\n16.\\nW.Steinitz,\\nTheModernChessInstructor\\n(EditionOlmsAG,1990).\\n17.\\nE.Lasker,\\nCommonSenseinChess\\n(DoverPublications,1965).\\n18.\\nJ.Knudsen,\\nEssentialChessQuotations\\n(iUniverse,2000).\\n19.\\nN.P.Jouppi,C.Young,N.Patil,\\netal.\\n,\\nProceedingsofthe44thAnnualInternationalSym-\\nposiumonComputerArchitecture\\n,ISCA'17(ACM,2017),pp.1Œ12.\\n20.\\nNotethattheoriginalAlphaGoZeropaperusedGPUstotraintheneuralnetworks.\\n21.\\nR.Coulom,\\nInternationalConferenceonComputersandGames\\n(2008),pp.113Œ124.\\n22.\\nTheprevalenceofdrawsinhigh-levelchesstendstocompresstheEloscale,comparedto\\nshogiorGo.\\n23.\\nisdesignedtoexploitCPUhardwareandcannotmakeuseofGPU/TPU,whereas\\nAlphaZeroisdesignedtoexploitGPU/TPUhardwareratherthanCPU.\\n24.\\nAgenerationTPUisroughlysimilarininferencespeedtoaTitanVGPU,although\\nthearchitecturesarenotdirectlycomparable.\\n25.\\nAlphaGoZerowasultimatelytrainedfor3.1millionstepsover40days.\\n26.\\nManyTCECopeningpositionsareunbalancedaccordingtobothAlphaZeroand\\nresultinginmorelossesforbothplayers.\\n27.\\nNewestavailableversionofasof13thofJanuary2018,from\\nhttps://github.com/official-stockfish/Stockfish/commit/\\nb508f9561cc2302c129efe8d60f201ff03ee72c8\\n.\\n28.\\nCerebellumopeningbookfrom\\nhttps://zipproth.de/#Brainfish_\\ndownload\\n.AlphaZerodidnotuseanopeningbook.Toensurediversityagainsta\\ndeterministicopeningbook,AlphaZerousedasmallamountofrandomizationinits\\nopeningmoves(\\n10\\n);thisavoidedduplicategamesbutalsoresultedinmorelosses.\\n29.\\nAperyqhapaq'sevaluationareavailableat\\nhttps://github.com/qhapaq-49/\\nqhapaq-bin/releases/tag/eloqhappa\\n.\\n30.\\nC.E.Shannon,\\nTheLondon,Edinburgh,andDublinPhilosophicalMagazineandJournal\\nofScience\\n41\\n,256(1950).\\n10\\n\", \"31.\\nO.Arenz,MonteCarlochess,Master'sthesis,TechnischeUniversitatDarmstadt(2012).\\n32.\\nO.E.David,N.S.Netanyahu,L.Wolf,\\nInternationalConferenceonNeuralNet-\\nworks\\n(Springer,2016),pp.88Œ96.\\nSupplementalReferences\\n33.\\nT.Marsland,\\nEncyclopediaofIntelligence\\n,S.Shapiro,ed.(JohnWiley&sons,\\nNewYork,1987).\\n34.\\nG.Tesauro,\\nIntelligence\\n134\\n,181(2002).\\n35.\\nG.Tesauro,G.R.Galperin,\\nAdvancesinNeuralInformationProcessingSystems9\\n(1996),\\npp.1068Œ1074.\\n36.\\nS.Thrun,\\nAdvancesinNeuralInformationProcessingSystems\\n(1995),pp.1069Œ1076.\\n37.\\nD.F.Beal,M.C.Smith,\\nInformationSciences\\n122\\n,3(2000).\\n38.\\nD.F.Beal,M.C.Smith,\\nTheoreticalComputerScience\\n252\\n,105(2001).\\n39.\\nJ.Baxter,A.Tridgell,L.Weaver,\\nMachineLearning\\n40\\n,243(2000).\\n40.\\nJ.Veness,D.Silver,A.Blair,W.Uther,\\nAdvancesinNeuralInformationProcessingSys-\\ntems\\n(2009),pp.1937Œ1945.\\n41.\\nT.Kaneko,K.Hoki,\\nAdvancesinComputerGames-13thInternationalConference,ACG\\n2011,Tilburg,TheNetherlands,November20-22,2011,RevisedSelectedPapers\\n(2011),\\npp.158Œ169.\\n42.\\nK.Hoki,T.Kaneko,\\nJournalofIntelligenceResearch(JAIR)\\n49\\n,527(2014).\\n43.\\nM.Lai,Giraffe:Usingdeepreinforcementlearningtoplaychess,Master'sthesis,Imperial\\nCollegeLondon(2015).\\n44.\\nT.Anthony,Z.Tian,D.Barber,\\nAdvancesinNeuralInformationProcessingSystems30\\n(2017),pp.5366Œ5376.\\n45.\\nD.E.Knuth,R.W.Moore,\\nIntelligence\\n6\\n,293Œ(1975).\\n46.\\nR.Ramanujan,A.Sabharwal,B.Selman,\\nProceedingsofthe26thConferenceonUncer-\\ntaintyinIntelligence(UAI)\\n(2010).\\n47.\\nC.D.Rosin,\\nAnnalsofMathematicsandIntelligence\\n61\\n,203(2011).\\n11\\n\", '48.\\nK.He,X.Zhang,S.Ren,J.Sun,\\n14thEuropeanConferenceonComputerVision\\n(2016),\\npp.630Œ645.\\n49.\\nTheTCECworldchampionshipdisallowsopeningbooksandinsteadstartstwogames(one\\nfromeachcolour)fromeachopeningposition.\\n50.\\nOnlinechessgamesdatabase,365chess(2017).URL:\\nhttps://www.365chess.\\ncom/\\n.\\n12\\n', 'Acknowledgments\\nWethankMatthewSadlerforanalysingchessgames;YoshiharuHabuforanalysingshogi\\ngames;LorrayneBennettfororganizationalassistance;BernhardKonrad,EdLockhartand\\nGeorgOstrovskiforreviewingthepaper;andtherestoftheDeepMindteamfortheirsupport.\\nFunding\\nAllresearchdescribedinthisreportwasfundedbyDeepMindandAlphabet.\\nAuthorcontributions\\nD.S.,J.S.,T.H.andI.A.designedtheAlphaZeroalgorithmwithadvicefromT.G.,A.G.,T.L.,\\nK.S.,M.Lai,L.S.,M.Lanctot;J.S.,I.A.,T.H.andM.LaiimplementedtheAlphaZeroprogram;\\nT.H.,J.S.,D.S.,M.Lai,I.A.,T.G.,K.S.,D.K.andD.H.ranexperimentsand/oranalyseddata;\\nD.S.,T.H.,J.S.,andD.H.managedtheproject.D.S.,J.S.,T.H.,M.Lai,I.A.andD.H.,wrotethe\\npaper.\\nCompetinginterests\\nTheauthorsdeclarenocompetinginterests.DeepMindhasthefollowingpatent\\napplicationsrelatedtothiswork:PCT/EP2018/063869;US15/280,711;US15/280,784.\\nDataandmaterialsavailability\\nAfulldescriptionofthealgorithminpseudocodeaswellasadditionalgamesbetweenAlp-\\nhaZeroandotherprogramsareavailableintheSupplementaryMaterials.\\nSupplementaryMaterials\\nŁ\\n110chessgamesbetweenAlphaZeroand8fromtheinitialboardposition.\\nŁ\\n100chessgamesbetweenAlphaZeroand8from2016TCECstartpositions.\\nŁ\\n100shogigamesbetweenAlphaZeroandElmofromtheinitialboardposition.\\nŁ\\nPseudocodedescriptionoftheAlphaZeroalgorithm.\\nŁ\\nDataforFigures1and3inJSONformat.\\nŁ\\nSupplementaryFiguresS1,S2,S3,S4andSupplementaryTablesS1,S2,S3,S4,S5,S6,\\nS7,S8,S9.\\nŁ\\nReferences(33-50).\\n13\\n', 'Methods\\nAnatomyofaComputerChessProgram\\nInthissectionwedescribethecomponentsofatypicalcomputerchessprogram,focusing\\non(\\n11\\n),anopensourceprogramthatwontheTCEC(Season9)com-\\nputerchessworldchampionshipin2016.Foranoverviewofstandardmethods,see(\\n33\\n).\\nEachposition\\ns\\nisdescribedbyasparsevectorofhandcraftedfeatures\\n˚\\n(\\ns\\n)\\n,including\\nmidgame/endgmaterialpointvalues,materialimbalancetables,piece-squareta-\\nbles,mobilityandtrappedpieces,pawnstructure,kingsafety,outposts,bishoppair,andother\\nmiscellaneousevaluationpatterns.Eachfeature\\n˚\\ni\\nisassigned,byacombinationofmanualand\\nautomatictuning,acorrespondingweight\\nw\\ni\\nandthepositionisevaluatedbyalinearcombi-\\nnation\\nv\\n(\\ns;w\\n)=\\n˚\\n(\\ns\\n)\\n>\\nw\\n.However,thisrawevaluationisonlyconsideredaccurateforposi-\\ntionsthatareﬁquietﬂ,withnounresolvedcapturesorchecks.Adomain-specialized\\nquiescence\\nsearch\\nisusedtoresolveongoingtacticalsituationsbeforetheevaluationfunctionisapplied.\\nTheevaluationofaposition\\ns\\niscomputedbyaminimaxsearchthatevaluateseachleaf\\nusingaquiescencesearch.Alpha-betapruningisusedtosafelycutanybranchthatisprovably\\ndominatedbyanothervariation.Additionalcutsareachievedusingaspirationwindowsand\\nprincipalvariationsearch.Otherpruningstrategiesincludenullmovepruning(whichassumes\\napassmoveshouldbeworsethananyvariation,inpositionsthatareunlikelytobein\\nzugzwang\\n,\\nasdeterminedbysimpleheuristics),futilitypruning(whichassumesknowledgeofthemaxi-\\nmumpossiblechangeinevaluation),andotherdomain-dependentpruningrules(whichassume\\nknowledgeofthevalueofcapturedpieces).\\nThesearchisfocusedonpromisingvariationsbothbyextendingthesearchdepthofpromis-\\ningvariations,andbyreducingthesearchdepthofunpromisingvariationsbasedonheuristics\\nlikehistory,static-exchangeevaluation(SEE),andmovingpiecetype.Extensionsarebasedon\\ndomain-independentrulesthatidentifysingularmoveswithnosensiblealternative,anddomain-\\ndependentrules,suchasextendingcheckmoves.Reductions,suchaslatemovereductions,are\\nbasedheavilyondomainknowledge.\\nTheefyofalpha-betasearchdependscriticallyupontheorderinwhichmovesare\\nconsidered.Movesarethereforeorderedbyiterativedeepening(usingashallowersearchto\\nordermovesforadeepersearch).Inaddition,acombinationofdomain-independentmove\\norderingheuristics,suchaskillerheuristic,historyheuristic,counter-moveheuristic,andalso\\ndomain-dependentknowledgebasedoncaptures(SEE)andpotentialcaptures(MVV/LVA).\\nAtranspositiontablefacilitatesthereuseofvaluesandmoveorderswhenthesameposition\\nisreachedbymultiplepaths.Insomevariants,acarefullytunedopeningbookmaybeused\\ntoselectmovesatthestartofthegame.Anendgametablebase,precalculatedbyexhaustive\\nretrogradeanalysisofendgamepositions,providestheoptimalmoveinallpositionswithsix\\nandsometimessevenpiecesorless.\\nOtherstrongchessprograms,andalsoearlierprogramssuchasDeepBlue(\\n1\\n),haveused\\nverysimilararchitectures(\\n33\\n)includingthemajorityofthecomponentsdescribedabove,al-\\n14\\n', \"thoughimportantdetailsvaryconsiderably.\\nNoneofthetechniquesdescribedinthissectionareusedbyAlphaZero.Itislikelythat\\nsomeofthesetechniquescouldfurtherimprovetheperformanceofAlphaZero;however,we\\nhavefocusedonapureself-playreinforcementlearningapproachandleavetheseextensions\\nforfutureresearch.\\nPriorWorkonComputerChessandShogi\\nInthissectionwediscusssomenotablepriorworkonreinforcementlearningand/ordeeplearn-\\ningincomputerchess,shogiand,duetoitshistoricalrelevance,backgammon.\\nTDGammon\\n(\\n6\\n)wasabackgammonprogramthatevaluatedpositionsbyamulti-layerper-\\nceptron,trainedbytemporal-differencelearningtopredictthegameoutcome.Whenits\\nevaluationfunctionwascombinedwitha3-plysearch(\\n34\\n)TDGammondefeatedthehuman\\nworldchampion.AsubsequentpaperintroducedtheversionofMonte-Carlosearch(\\n35\\n),\\nwhichevaluatedrootpositionsbytheaverageoutcomeof\\nn\\n-steprollouts.Eachrolloutwasgen-\\neratedbygreedymoveselectionandthe\\nn\\nthpositionwasevaluatedbyTDGammon'sneural\\nnetwork.\\nNeuroChess\\n(\\n36\\n)evaluatedpositionsbyaneuralnetworkthatused175handcraftedinput\\nfeatures.Itwastrainedbytemporal-differencelearningtopredictthegameoutcome,and\\nalsotheexpectedfeaturesaftertwomoves.\\nNeuroChess\\nwon13%ofgamesagainst\\nGnuChess\\nusingaeddepth2search,butlostoverall.\\nBealandSmithappliedtemporal-differencelearningtoestimatethepiecevaluesinchess(\\n37\\n)\\nandshogi(\\n38\\n),startingfromrandomvaluesandlearningsolelybyself-play.\\nKnightCap\\n(\\n39\\n)evaluatedpositionsbyaneuralnetworkthatusedanattacktablebased\\nonknowledgeofwhichsquaresareattackedordefendedbywhichpieces.Itwastrainedby\\navariantoftemporal-differencelearning,knownasTD(leaf),thatupdatestheleafvalueof\\ntheprincipalvariationofanalpha-betasearch.\\nKnightCap\\nachievedhumanmasterlevelafter\\ntrainingagainstastrongcomputeropponentwithhand-initializedpiece-valueweights.\\nMeep\\n(\\n40\\n)evaluatedpositionsbyalinearevaluationfunctionbasedonhandcraftedfeatures.\\nItwastrainedbyanothervariantoftemporal-differencelearning,knownasTreeStrap,that\\nupdatesallnodesofanalpha-betasearch.\\nMeep\\ndefeatedhumaninternationalmasterplayersin\\n13outof15games,aftertrainingbyself-playwithrandomlyinitializedweights.\\nKanekoandHoki(\\n41\\n)trainedtheweightsofashogievaluationfunctioncomprisingamil-\\nlionfeatures,bylearningtoselectexperthumanmovesduringalpha-betasearch.Theyalsoper-\\nformedalarge-scaleoptimizationbasedonminimaxsearchregulatedbyexpertgamelogs(\\n42\\n);\\nthisformedpartofthe\\nBonanza\\nenginethatwonthe2013WorldComputerShogiChampi-\\nonship.\\nGiraffe\\n(\\n43\\n)evaluatedpositionsbyaneuralnetworkthatincludedmobilitymapsandattack\\nanddefendmapsdescribingthelowestvaluedattackeranddefenderofeachsquare.Itwas\\ntrainedbyself-playusingTD(leaf),alsoreachingastandardofplaycomparabletointernational\\nmasters.\\n15\\n\", \"DeepChess\\n(\\n32\\n)trainedaneuralnetworktoperformpair-wiseevaluationsofpositions.It\\nwastrainedbysupervisedlearningfromadatabaseofhumanexpertgamesthatwas\\ntoavoidcapturemovesanddrawngames.\\nDeepChess\\nreachedastronggrandmasterlevelof\\nplay.\\nAlloftheseprogramscombinedtheirlearnedevaluationfunctionswithanalpha-betasearch\\nenhancedbyavarietyofextensions.\\nBycontrast,anapproachbasedontrainingdualpolicyandvaluenetworksusingapolicy\\niterationalgorithmsimilartoAlphaZerowassuccessfullyappliedtothegameHex(\\n44\\n).This\\nworkdifferedfromAlphaZeroinseveralregards:thepolicynetworkwasinitializedbyimitating\\napre-existingMCTSsearchalgorithm,augmentedbyrollouts;thenetworkwassubsequently\\nretrainedfromscratchateachiteration;andvaluetargetswerebasedontheoutcomeofself-play\\ngamesusingtherawpolicynetwork,ratherthanMCTSsearch.\\nMCTSandAlpha-BetaSearch\\nForatleastfourdecadesthestrongestcomputerchessprogramshaveusedalpha-betasearch\\nwithhandcraftedevaluationfunctions(\\n33,45\\n).ChessprogramsusingtraditionalMCTS(\\n31\\n)\\nweremuchweakerthanalpha-betasearchprograms(\\n46\\n),whereasalpha-betaprogramsbased\\nonneuralnetworkshavepreviouslybeenunabletocompetewithfaster,handcraftedevalua-\\ntionfunctions.Surprisingly,AlphaZerosurpassedpreviousapproachesbyusinganeffective\\ncombinationofMCTSandneuralnetworks.\\nAlphaZeroevaluatespositionsnon-linearlyusingdeepneuralnetworks,ratherthanthelin-\\nearevaluationfunctionusedintypicalchessprograms.Thisprovidesamorepowerfulevalua-\\ntionfunction,butmayalsointroducelargerworst-casegeneralizationerrors.Whencombined\\nwithalpha-betasearch,whichcomputesanexplicitminimax,thebiggesterrorsaretypically\\npropagateddirectlytotherootofthesubtree.Bycontrast,AlphaZero'sMCTSaveragesover\\nthepositionevaluationswithinasubtree,ratherthancomputingtheminimaxevaluationofthat\\nsubtree.Wespeculatethattheapproximationerrorsintroducedbyneuralnetworkstherefore\\ntendtocanceloutwhenevaluatingalargesubtree.\\nDomainKnowledge\\nAlphaZerowasprovidedwiththefollowingdomainknowledgeabouteachgame:\\n1.\\nTheinputfeaturesdescribingtheposition,andtheoutputfeaturesdescribingthemove,\\narestructuredasasetofplanes;i.e.theneuralnetworkarchitectureismatchedtothe\\ngrid-structureoftheboard.\\n2.\\nAlphaZeroisprovidedwithperfectknowledgeofthegamerules.Theseareusedduring\\nMCTS,tosimulatethepositionsresultingfromasequenceofmoves,todeterminegame\\ntermination,andtoscoreanysimulationsthatreachaterminalstate.\\n16\\n\", \"3.\\nKnowledgeoftherulesisalsousedtoencodetheinputplanes(i.e.castling,repetition,\\nno-progress)andoutputplanes(howpiecesmove,promotions,andpiecedropsinshogi).\\n4.\\nThetypicalnumberoflegalmovesisusedtoscaletheexplorationnoise(seebelow).\\n5.\\nChessandshogigamesexceeding512stepswereterminatedandassignedadrawnout-\\ncome;Gogamesexceeding722stepswereterminatedandscoredwithTromp-Taylor\\nrules,similarlytopreviouswork(\\n9\\n).\\nAlphaZerodidnotuseanopeningbook,endgametablebases,orheuristics.\\nSearch\\nWedescribeheretheMCTSalgorithm(\\n9\\n)usedbyAlphaZero;furtherdetailscanbe\\nfoundinthepseudocodeintheSupplementaryData.Eachstate-actionpair\\n(\\ns;a\\n)\\nstoresa\\nsetofstatistics,\\nf\\nN\\n(\\ns;a\\n)\\n;W\\n(\\ns;a\\n)\\n;Q\\n(\\ns;a\\n)\\n;P\\n(\\ns;a\\n)\\ng\\n,where\\nN\\n(\\ns;a\\n)\\nisthevisitcount,\\nW\\n(\\ns;a\\n)\\nisthetotalaction-value,\\nQ\\n(\\ns;a\\n)\\nisthemeanaction-value,and\\nP\\n(\\ns;a\\n)\\nisthepriorprobabil-\\nityofselecting\\na\\nin\\ns\\n.Eachsimulationbeginsattherootnodeofthesearchtree,\\ns\\n0\\n,and\\nwhenthesimulationreachesaleafnode\\ns\\nL\\nattime-step\\nL\\n.Ateachofthesetime-\\nsteps,\\nt<L\\n,anactionisselected,\\na\\nt\\n=argmax\\na\\n\\nQ\\n(\\ns\\nt\\n;a\\n)+\\nU\\n(\\ns\\nt\\n;a\\n)\\n\\n,usingavariant\\nofthePUCTalgorithm(\\n47\\n),\\nU\\n(\\ns;a\\n)=\\nC\\n(\\ns\\n)\\nP\\n(\\ns;a\\n)\\np\\nN\\n(\\ns\\n)\\n=\\n(1+\\nN\\n(\\ns;a\\n))\\n,where\\nN\\n(\\ns\\n)\\nis\\ntheparentvisitcountand\\nC\\n(\\ns\\n)\\nistheexplorationrate,whichgrowsslowlywithsearchtime,\\nC\\n(\\ns\\n)=log((1+\\nN\\n(\\ns\\n)+\\nc\\nbase\\n)\\n=c\\nbase\\n)+\\nc\\ninit\\n,butisessentiallyconstantduringthefasttraining\\ngames.Theleafnode\\ns\\nL\\nisaddedtoaqueueforneuralnetworkevaluation,\\n(\\np\\n;v\\n)=\\nf\\n\\n(\\ns\\nL\\n)\\n.\\nTheleafnodeisexpandedandeachstate-actionpair\\n(\\ns\\nL\\n;a\\n)\\nisinitializedto\\nf\\nN\\n(\\ns\\nL\\n;a\\n)=\\n0\\n;W\\n(\\ns\\nL\\n;a\\n)=0\\n;Q\\n(\\ns\\nL\\n;a\\n)=0\\n;P\\n(\\ns\\nL\\n;a\\n)=\\np\\na\\ng\\n.Thevisitcountsandvaluesarethenup-\\ndatedinabackwardpassthrougheachstep\\nt\\n\\nL\\n,\\nN\\n(\\ns\\nt\\n;a\\nt\\n)=\\nN\\n(\\ns\\nt\\n;a\\nt\\n)+1\\n;W\\n(\\ns\\nt\\n;a\\nt\\n)=\\nW\\n(\\ns\\nt\\n;a\\nt\\n)+\\nv;Q\\n(\\ns\\nt\\n;a\\nt\\n)=\\nW\\n(\\ns\\nt\\n;a\\nt\\n)\\nN\\n(\\ns\\nt\\n;a\\nt\\n)\\n.\\nRepresentation\\nInthissectionwedescribetherepresentationoftheboardinputs,andtherepresentationofthe\\nactionoutputs,usedbytheneuralnetworkinAlphaZero.Otherrepresentationscouldhavebeen\\nused;inourexperimentsthetrainingalgorithmworkedrobustlyformanyreasonablechoices.\\nTheinputtotheneuralnetworkisan\\nN\\n\\nN\\n\\n(\\nMT\\n+\\nL\\n)\\nimagestackthatrepresentsstate\\nusingaconcatenationof\\nT\\nsetsof\\nM\\nplanesofsize\\nN\\n\\nN\\n.Eachsetofplanesrepresents\\ntheboardpositionatatime-step\\nt\\n\\nT\\n+1\\n;:::;t\\n,andissettozerofortime-stepslessthan\\n1.Theboardisorientedtotheperspectiveofthecurrentplayer.The\\nM\\nfeatureplanesare\\ncomposedofbinaryfeatureplanesindicatingthepresenceoftheplayer'spieces,withoneplane\\nforeachpiecetype,andasecondsetofplanesindicatingthepresenceoftheopponent'spieces.\\nForshogithereareadditionalplanesindicatingthenumberofcapturedprisonersofeachtype.\\nThereareanadditional\\nL\\nconstant-valuedinputplanesdenotingtheplayer'scolour,themove\\n17\\n\", \"number,andthestateofspecialrules:thelegalityofcastlinginchess(kingsideorqueenside);\\ntherepetitioncountforthecurrentposition(3repetitionsisanautomaticdrawinchess;4in\\nshogi);andthenumberofmoveswithoutprogressinchess(50moveswithoutprogressisan\\nautomaticdraw).InputfeaturesaresummarizedinTableS1.\\nAmoveinchessmaybedescribedintwoparts:selectingthepiecetomove,andthen\\nselectingamongpossiblemovesforthatpiece.Werepresentthepolicy\\nˇ\\n(\\na\\nj\\ns\\n)\\nbya\\n8\\n\\n8\\n\\n73\\nstackofplanesencodingaprobabilitydistributionover4,672possiblemoves.Eachofthe\\n8\\n\\n8\\npositionsthesquarefromwhichtoﬁpickupﬂapiece.The56planesencode\\npossible`queenmoves'foranypiece:anumberofsquares\\n[1\\n::\\n7]\\ninwhichthepiecewillbe\\nmoved,alongoneofeightrelativecompassdirections\\nf\\nN;NE;E;SE;S;SW;W;NW\\ng\\n.The\\nnext8planesencodepossibleknightmovesforthatpiece.The9planesencodepossible\\nunderpromotionsforpawnmovesorcapturesintwopossiblediagonals,toknight,bishopor\\nrookrespectively.Otherpawnmovesorcapturesfromtheseventhrankarepromotedtoa\\nqueen.\\nThepolicyinshogiisrepresentedbya\\n9\\n\\n9\\n\\n139\\nstackofplanessimilarlyencodinga\\nprobabilitydistributionover11,259possiblemoves.The64planesencode`queenmoves'\\nandthenext2planesencodeknightmoves.Anadditional\\n64+2\\nplanesencodepromoting\\nqueenmovesandpromotingknightmovesrespectively.Thelast7planesencodeacaptured\\npiecedroppedbackintotheboardatthatlocation.\\nThepolicyinGoisrepresentedidenticallytoAlphaGoZero(\\n9\\n),usingadistribution\\nover\\n19\\n\\n19+1\\nmovesrepresentingpossiblestoneplacementsandthepassmove.Wealso\\ntriedusingadistributionovermovesforchessandshogi;theresultwasalmostidentical\\nalthoughtrainingwasslightlyslower.\\nIllegalmovesaremaskedoutbysettingtheirprobabilitiestozero,andre-normalisingthe\\nprobabilitiesovertheremainingsetoflegalmoves.\\nTheactionrepresentationsaresummarizedinTableS2.\\nArchitecture\\nApartfromtherepresentationofpositionsandactionsdescribedabove,AlphaZerousesthe\\nsamenetworkarchitectureasAlphaGoZero(\\n9\\n),recapitulatedhere.\\nTheneuralnetworkconsistsofaﬁbodyﬂfollowedbybothpolicyandvalueﬁheadsﬂ.The\\nbodyconsistsofabatch-normalizedconvolutionallayerfollowedby19residualblocks(\\n48\\n).\\nEachsuchblockconsistsoftwobatch-normalizedconvolutionallayerswithaskipcon-\\nnection.Eachconvolutionapplies256ofkernelsize\\n3\\n\\n3\\nwithstride1.Thepolicyhead\\nappliesanadditionalbatch-normalizedconvolutionallayer,followedbyacon-\\nvolutionof73forchessor139forshogi,oralinearlayerofsize362forGo,\\nrepresentingthelogitsoftherespectivepoliciesdescribedabove.Thevalueheadappliesan\\nadditionalbatch-normalizedconvolutionof\\n1\\nofkernelsize\\n1\\n\\n1\\nwithstride1,\\nfollowedbyalinearlayerofsize256anda\\ntanh\\n-linearlayerofsize1.\\n18\\n\", \"\\nDuringtraining,eachMCTSused800simulations.Thenumberofgames,positions,andthink-\\ningtimevariedpergameduelargelytodifferentboardsizesandgamelengths,andareshown\\ninTableS3.Thelearningratewassetto0.2foreachgame,andwasdroppedthreetimesduring\\nthecourseoftrainingto0.02,0.002and0.0002respectively,after100,300and500thousands\\nofstepsforchessandshogi,andafter0,300and500thousandsofstepsforGo.Movesare\\nselectedinproportiontotherootvisitcount.DirichletnoiseDir\\n(\\n\\n)\\nwasaddedtotheprior\\nprobabilitiesintherootnode;thiswasscaledininverseproportiontotheapproximatenumber\\noflegalmovesinatypicalposition,toavalueof\\n\\n=\\nf\\n0\\n:\\n3\\n;\\n0\\n:\\n15\\n;\\n0\\n:\\n03\\ng\\nforchess,shogiand\\nGorespectively.Positionswerebatchedacrossparalleltraininggamesforevaluationbythe\\nneuralnetwork.Unlessotherwisethetrainingandsearchalgorithmandparameters\\nareidenticaltoAlphaGoZero(\\n9\\n).\\nDuringevaluation,AlphaZeroselectsmovesgreedilywithrespecttotherootvisitcount.\\nEachMCTSwasexecutedonasinglemachinewith4TPUs.\\nOpponents\\nToevaluateperformanceinchess,weusedversion8(ofLinuxrelease)asa\\nbaselineprogram.wasaccordingtoits2016TCECworldchampionship\\nsettings:44threadson44cores(two2.2GHzIntelXeonBroadwellCPUswith22\\ncores),ahashsizeof32GB,syzygyendgametablebases,at3hourtimecontrolswith15addi-\\ntionalsecondspermove.Wealsoevaluatedagainstthemostrecentversion,9(just\\nreleasedattimeofwriting),usingthesame\\ndoesnothaveanopeningbookofitsownandallprimaryevaluationswereper-\\nformedwithoutanopeningbook.Wealsoperformedonesecondaryevaluationinwhichthe\\nopponent'sopeningmoveswereselectedbythe\\nBr\\nprogram,usinganopeningbookde-\\nrivedfromHowever,wenotethatthesematcheswerelowindiversity,andAlphaZero\\nandtendedtoproduceverysimilargamesthroughoutthematch,morethan90%of\\nwhichweredraws.WhenweforcedAlphaZerotoplaywithgreaterdiversity(bysoftmaxsam-\\nplingwithatemperatureof10.0amongmovesforwhichthevaluewasnomorethan1%away\\nfromthebestmoveforthe30plies)thewinningrateincreasedfrom5.8%to14%.\\nToevaluateperformanceinshogi,weusedElmoversionWCSC27incombinationwith\\nYaneuraOu2017EarlyKPPT4.7964AVX2TOURNAMENTasabaselineprogram,using44\\nCPUthreads(ontwo2.2GHzIntelXeonBroadwellCPUswith22cores)andahashsizeof\\n32GBwiththeusioptionsofEnteringKingRulesettoCSARule27,MinimumThinkingTime\\nsetto\\n1000\\n,BookFilesettostandard\\nbook.db,BookDepthLimitsetto\\n0\\nandBookMovessetto\\n200\\n.Additionally,wealsoevaluatedagainstAperyqhapaqcombinedwiththesameYaneuraOu\\nversionandnobookForAperyqhapaq,weusedthesameusioptionsasforElmoexcept\\nforthebooksetting.\\n19\\n\", 'Matchconditions\\nWemeasuredthehead-to-headperformanceofAlphaZeroinmatchesagainsteachoftheabove\\nopponents(Figure2).Threetypesofmatchwereplayed:startingfromtheinitialboardposition\\n(thedefaultunlessotherwisestartingfromhumanopeningpositions;\\norstartingfromthe2016TCECopeningpositions(\\n49\\n).\\nThemajorityofmatchesforchess,shogiandGousedthe2016TCECtimecon-\\ntrols:3hoursofmainthinkingtime,plus15additionalsecondsofthinkingtimeforeachmove.\\nWealsoinvestigatedasymmetrictimecontrols(Figure2B),wheretheopponentreceived3\\nhoursofmainthinkingtimebutAlphaZeroreceivedonlyafractionofthistime.Finally,for\\nshogionly,weranamatchusingfastertimecontrolsusedinthe2017CSAworldchampionship:\\n10minutespergameplus10secondspermove.\\nAlphaZerousedasimpletimecontrolstrategy:thinkingfor\\n1\\n=\\n20\\nthoftheremainingtime.\\nOpponentprogramsusedcustomized,sophisticatedheuristicsfortimecontrol.Ponderingwas\\ndisabledforallplayers(particularlyimportantfortheasymmetrictimecontrolsinFigure2).\\nResignationwasenabledforallplayers(-650centipawnsfor4consecutivemovesforStock-\\n-4,500centipawnsfor10consecutivemovesforElmo,oravalueof-0.9forAlphaZero\\nandAlphaGoLee).\\nMatchesconsistedof1,000games,exceptforthehumanopenings(200gamesasblackand\\n200gamesaswhitefromeachopening)andthe2016TCECopenings(50gamesasblackand\\n50gamesaswhitefromeachofthe50openings).Thehumanopeningpositionswerechosen\\nasthoseplayedmorethan100,000timesinanonlinedatabase(\\n50\\n).\\nEloratings\\nWeevaluatedtherelativestrengthofAlphaZero(Figure1)bymeasuringtheEloratingofeach\\nplayer.Weestimatetheprobabilitythatplayer\\na\\nwilldefeatplayer\\nb\\nbyalogisticfunction\\np\\n(\\na\\ndefeats\\nb\\n)=(1+10\\n(\\nc\\nelo\\n(\\ne\\n(\\nb\\n)\\n\\ne\\n(\\na\\n)))\\n)\\n\\n1\\n,andestimatetheratings\\ne\\n(\\n\\n)\\nbyBayesianlogistic\\nregression,computedbythe\\nBayesElo\\nprogram(\\n21\\n)usingthestandardconstant\\nc\\nelo\\n=1\\n=\\n400\\n.\\nEloratingswerecomputedfromtheresultsofa1secondpermovetournamentbetween\\niterationsofAlphaZeroduringtraining,andalsoabaselineplayer:eitherElmoor\\nAlphaGoLeerespectively.TheEloratingofthebaselineplayerswasanchoredtopublicly\\navailablevalues(\\n9\\n).\\nInordertocompareEloratingsat1secondpermovetimecontrolstostandardEloratings\\natfulltimecontrols,wealsoprovidetheresultsofvs.andElmovs.Elmo\\nmatches(TableS5).\\nExamplegames\\nTheSupplementaryDataincludes110gamesfromthemainchessmatchbetweenAlphaZero\\nandstartingfromtheinitialboardposition;100gamesfromthechessmatchstarting\\n20\\n', 'from2016TCECworldchampionshipopeningpositions;and100gamesfromthemainshogi\\nmatchbetweenAlphaZeroandElmo.Forthechessmatchfromtheinitialboardposition,one\\ngamewasselectedatrandomforeachuniqueopeningsequenceof30plies;allAlphaZero\\nlosseswerealsoincluded.FortheTCECmatch,onegameaswhiteandonegameasblack\\nwereselectedatrandomfromthematchstartingfromeachopeningposition.Fortheshogi\\nmatch,onegamewasselectedatrandomforeachuniqueopeningsequenceof25plies(when\\nAlphaZerowasblack)or10plies(whenAlphaZerowaswhite).\\n10chessgameswereindependentlyselectedfromeachbatchbyGMMatthewSadler,ac-\\ncordingtotheirinteresttothechesscommunity;thesegamesareincludedinTableS6.Simi-\\nlarly,10shogigameswereindependentlyselectedbyYoshiharuHabu;thesegamesareincluded\\ninTableS7.\\n21\\n', 'FigureS1:\\nLearningcurvesshowingtheEloperformanceduringtraininginGo.\\nCom-\\nparisonbetweenAlphaZero,aversionofAlphaZerothatexploitsknowledgeofsymmetriesin\\nasimilarmannertoAlphaGoZero,andthepreviouslypublishedAlphaGoZero.AlphaZero\\ngeneratesapproximately\\n1\\n=\\n8\\nasmanypositionspertrainingstep,andthereforeuseseighttimes\\nmorewallclocktime,thanthesymmetry-augmentedalgorithms.\\n22\\n', 'FigureS2:\\nChessandshogiopeningspreferredbyAlphaZeroatdifferentstagesofself-\\nplaytraining\\n,labelledwiththenumberoftrainingsteps.Theshowsthemostfrequently\\nselectedopening6pliesplayedbyAlphaZeroduringitsgamesofself-play.Eachmovewas\\ngeneratedbyanMCTSwithjust800simulationspermove.\\n23\\n', 'FigureS3:\\nRepeatabilityofAlphaZerotrainingonthegameofchess.\\nTheshows6\\nseparatetrainingrunsof400,000steps(approximately4hourseach).Eloratingswerecom-\\nputedfromatournamentbetweenbaselineplayersandAlphaZeroplayersatdifferentstagesof\\ntraining.AlphaZeroplayersweregiven800simulationspermove.Similarrepeatabilitywas\\nobservedinshogiandGo.\\n24\\n', \"FigureS4:\\nChessmatchesbeginningfromthe2016TCECworldchampionshipstartpo-\\nsitions.\\nIntheleftbar,AlphaZeroplayswhite,startingfromthegivenposition;intherightbar\\nAlphaZeroplaysblack.EachbarshowstheresultsfromAlphaZero'sperspective:win(green),\\ndraw(grey),loss(red).Manyofthesestartpositionsareunbalancedaccordingtobothand\\nAlphaZeroandresultinginmorelossesforbothplayers.\\n25\\n\", 'Go\\nChess\\nShogi\\nFeaturePlanes\\nFeaturePlanes\\nFeaturePlanes\\nP1stone1\\nP1piece6\\nP1piece14\\nP2stone1\\nP2piece6\\nP2piece14\\nRepetitions2\\nRepetitions3\\nP1prisonercount7\\nP2prisonercount7\\nColour1\\nColour1\\nColour1\\nTotalmovecount1\\nTotalmovecount1\\nP1castling2\\nP2castling2\\nNo-progresscount1\\nTotal17\\nTotal119\\nTotal362\\nTableS1:InputfeaturesusedbyAlphaZeroinGo,chessandshogirespectively.Theset\\noffeaturesarerepeatedforeachpositionina\\nT\\n=8\\n-stephistory.Countsarerepresentedby\\nasinglereal-valuedinput;otherinputfeaturesarerepresentedbyaone-hotencodingusingthe\\nnumberofbinaryinputplanes.ThecurrentplayerisdenotedbyP1andtheopponent\\nbyP2.\\nChess\\nShogi\\nFeaturePlanes\\nFeaturePlanes\\nQueenmoves56\\nQueenmoves64\\nKnightmoves8\\nKnightmoves2\\nUnderpromotions9\\nPromotingqueenmoves64\\nPromotingknightmoves2\\nDrop7\\nTotal73\\nTotal139\\nTableS2:ActionrepresentationusedbyAlphaZeroinchessandshogirespectively.Thepolicy\\nisrepresentedbyastackofplanesencodingaprobabilitydistributionoverlegalmoves;planes\\ncorrespondtotheentriesinthetable.\\n26\\n', 'ChessShogiGo\\nMini-batches700k700k700k\\nTrainingTime9h12h13d\\nTrainingGames44million24million140million\\nThinkingTime800sims800sims800sims\\n˘\\n40ms\\n˘\\n80ms\\n˘\\n200ms\\nTableS3:SelectedstatisticsofAlphaZerotraininginchess,shogiandGo.\\nProgramChessShogiGo\\nAlphaZero63k(13k)58k(12k)16k(0.6k)\\n58,100k(24,000k)\\nElmo25,100k(4,600k)\\nAlphaZero1.5GFlop1.9GFlop8.5GFlop\\nTableS4:Evaluationspeed(positions/second)ofAlphaZero,andElmoinchess,\\nshogiandGo.Evaluationspeedistheaverageoverentiregamesatfulltimecontrolsfrom\\ntheinitialboardposition(themainevaluationinFigure2),standarddeviationsareshownin\\nparentheses.Bottomrow:NumberofoperationsusedbyAlphaZeroforoneevaluation.\\nProgramWinDrawLoss\\n57.1%42.9%0.0%\\nElmo98.7%1.0%0.3%\\nTableS5:PerformancecomparisonofandElmo,whenusingfulltimecontrolsof3h\\npergame,comparedtotimecontrolsof1spermove.\\n27\\n', 'Game1-White:AlphaZeroBlack:\\n1.Nf3Nf62.c4e63.Nc3Bb44.Qc2O-O5.a3Bxc36.Qxc3a57.b4d68.e3Ne49.Qc2Ng510.b5Nxf3+11.gxf3Qf612.d4Qxf313.Rg1Nd714.Be2Qf615.Bb2Qh416.Rg4\\nQxh217.Rg3f518.O-O-ORf719.Bf3Qh420.Rh1Qf621.Kb1g622.Rgg1a423.Ka1Rg724.e4f425.c5Qe726.Rc1Nf627.e5dxe528.Rhe1e429.Bxe4Qf830.d5exd531.\\nBd3Bg432.f3Bd733.Qc3Nh534.Re5c635.Rce1Nf636.Qd4cxb537.Bb1Bc638.Re6Rf739.Rg1Qg740.Qxf4Re841.Rd6Nd742.Qc1Rf643.f4Qe744.Rxf6Nxf645.f5\\nQe346.fxg6Qxc147.gxh7+Kf748.Rxc1Nxh749.Bxh7Re350.Rd1Ke851.Ka2Bd752.Bd4Rh353.Bc2Be654.Re1Kd755.Kb2Rf356.Re5Rg357.Re3Rg258.Kc3Rg459.\\nRf3Ke860.Rf2Rg3+61.Kb4Rg462.Rd2Bd763.Ka5Rf464.Be5Rf365.Rd3Rf266.Bd1Bc667.Kb61-0\\nGame2-White:AlphaZeroBlack:\\n1.d4Nf62.c4e63.Nf3b64.g3Bb75.Bg2Be76.Nc3O-O7.O-ONe48.Bd2d59.cxd5exd510.Qb3c511.Bf4Na612.Rfd1c413.Qc2Nb414.Qc1Qd715.h4Rac816.a3\\nNxc317.bxc3Nc618.Qb1Rce819.Re1Na520.Ng5f521.Nf3Bf622.Ra2h623.a4Qe624.Kh2Bc825.Rh1Nc626.h5Kh827.Ng1Qf728.Bf3Rd829.Nh3Kg830.Bc1Rfe8\\n31.Qb5Bb732.Rd1Na533.Qb1Bc834.Nf4Bg535.Ng6Bxc136.Qxc1Be637.Ne5Qc738.Rb2Nb739.Rb5Na540.Qf4Nb341.Ng6Qc642.Qe5Qd743.e3Na544.Bg2Nb7\\n45.Ra1Kh746.Nf4Bg847.Rxd5Bxd548.Qxd5Nd649.Bh3Re750.Ng6Rf751.Ne5Qb752.Bg2Qxd553.Bxd5Rc754.Kg2Ne455.Bxe4fxe456.f3exf3+57.Kxf3Re758.\\nNg6Rb759.e4b560.axb5Rxb561.Nf4Rb362.Ne2Ra863.e5a564.d5a465.d6a366.d7Kg867.Rd1Rbb868.e6Kf869.Nd41-0\\nGame3-White:AlphaZeroBlack:\\n1.d4Nf62.c4e63.Nf3b64.g3Bb75.Bg2Bb4+6.Bd2Be77.Nc3O-O8.Qc2Na69.a3c510.d5exd511.Ng5Nc712.h4h613.Nxd5Ncxd514.cxd5d615.a4Qd716.Bc3Rfe8\\n17.O-O-OBd818.e4Ng419.Bh3hxg520.f3f521.fxg4fxg422.Bf1gxh423.Bb5Qf724.gxh4Bf625.Rhf1Rf826.Bxf6gxf627.Rf4Qg728.Be2Qh629.Rdf1g330.Qd3Kh8\\n31.Qxg3Rae832.Bd3Bc833.Kb1Rf734.Qf2Bd735.h5Ref836.Bc2Be837.Rf3Re738.Rxf6Qxf639.Qxf6+Rxf640.Rxf6Kg741.Rxd6Bxh542.Kc1Re543.a5bxa544.\\nKd2Be845.Ra6Rh546.Bd3a447.d6Bf748.d7Rh849.e51-0\\nGame4-White:AlphaZeroBlack:\\n1.Nf3e62.c4Nf63.Nc3Bb44.Qc2O-O5.a3Bxc36.Qxc3d67.b4e58.Bb2Nbd79.e3Re810.d3Nf811.Be2a512.O-OBg413.h3Bh514.Qc2h615.Bc3b616.b5N6d717.\\nRad1Nc518.Ba1Bg619.Qb2Na420.Qa2Nc521.d4exd422.Nxd4Be423.Bf3Bxf324.gxf3Nfe625.Kh2Nxd426.Rxd4Kh727.Qc2+g628.Rf4Qe729.Rg1Rg830.h4h531.\\nRg5Kh632.e4Ne633.Rf6Nxg534.hxg5+Kh735.f4Rae836.Qd3Rg737.f3Kg838.Qd4Kf839.Bc3Rg840.a4Rd841.Kh3Rd742.f5gxf543.Rxf5Qe644.Kh4Re745.Qd5\\nRg646.Kxh5Re847.Bf6Qd748.Kg4Rc849.Qc6Qe850.Qxe8+Kxe851.Rd5Rxf652.gxf6Kd753.Kf5c654.bxc6+Kxc655.f4Rh856.e51-0\\nGame5-White:AlphaZeroBlack:\\n1.d4Nf62.Nf3e63.c4b64.g3Bb75.Bg2Bb4+6.Bd2Be77.Nc3c68.Bf4O-O9.e4d510.e5Ne411.cxd5cxd512.O-ONxc313.bxc3Ba614.Re1Nc615.h4Rc816.Re3Rc7\\n17.Ng5h618.Nh3Kh719.Rf3Na520.Qc2+Kg821.Re1Kh822.Qd1Nc623.Be3Bc424.Qd2Kh725.Nf4Qe826.g4Rh827.Nh5Kg828.Rh3Rb729.Bf4Bf830.Qd1Ne731.\\nBc1b532.f4Rb633.Ba3Ng634.Bxf8Nxf835.Qd2Qc836.Rf3Qd837.Qf2b438.cxb4Rxb439.f5Qc740.Rd1Qb741.Rd2Qc742.Qg3Bb543.Kh2Bd744.Qf2Rb645.Rc2\\nRc646.Rb2Rb647.Bf1Qb848.Rxb6axb649.f6g650.Ng3Be851.Qb2Qd852.h5Nd753.Kg2g554.Rc3Nxf655.exf6Qxf656.Rf3Qd857.Qb4Kg758.Be2Bc659.Rb3Bd7\\n60.Qd6Ba461.Qxd8Rxd862.Rxb6Kf863.Kf2Rc864.Ra6Bd765.Ra7Ke866.Bd3Rc367.Ke2Kd868.Kd2Rc769.Rxc7Kxc770.Kc3Ba471.Kb4Bd172.Be2Bc273.Nf1\\n1-0\\nGame6-White:AlphaZeroBlack:\\n1.Nf3Nf62.c4c53.Nc3e64.g3Qb65.d3d56.Bg2Be77.cxd5exd58.e4d49.Nd5Nxd510.exd5O-O11.O-OBg412.h3Bxf313.Qxf3Na614.h4Bd615.h5Qd816.h6g6\\n17.Re1Nc718.Bd2a519.a4b620.Re2Re821.Rxe8+Nxe822.Re1Rb823.b3Nc724.Re2Ra825.Kf1Rb826.Bh3Ra827.Re4Rb828.Re1Ra829.Bc1Rb830.Re2Bf831.\\nRe5Bd632.Re1Bf833.Bg2Bd634.Bd2Rc835.Bf4Qd736.g4Re837.Re4Rd838.Bg5Re839.Qf6Bf840.Qc6Qxc641.dxc6Bd642.f4Kf843.f5gxf544.gxf5Rxe445.Bxe4\\nBe546.f6Kg847.Bf5Ne848.Kf2Bc749.Kf3Bb850.Bf4Bxf451.Kxf41-0\\nGame7-White:AlphaZeroBlack:\\n1.Nf3Nf62.c4e63.Nc3d54.d4c65.Bg5Be76.e3h67.Bf4O-O8.Qc2Nbd79.g4dxc410.Rg1Nd511.g5Nxf412.gxh6Nh513.hxg7Nxg714.O-O-OQa515.Bxc4Qf516.\\nQe2Qh717.Rg3Kh818.Rdg1Nf519.Qf1Nxg320.Rxg3Rg821.Rh3Rg722.Rxh7+Rxh723.Bd3Rg724.Qd1Nf625.Ne5Bd726.Qf3Rf827.Ne2Kg828.a3Be829.Kb1a5\\n30.e4b531.Bc2b432.a4Kh833.Ka2Kg834.Ng3Rg535.Qd1Kh836.Bb3Rg737.Qc2Ng438.Nxc6Bxc639.Qxc6Rh740.Qc7Bd841.Qf4Rg842.Bd1Nf643.h4Nd744.h5\\nNf645.d5Re846.d6Rg747.h6Rh748.e5Nd549.Qd2Rg850.Bb3Bg551.Qd1Nb652.Ne41-0\\nGame8-White:Black:AlphaZero\\n1.e4e52.Nf3Nc63.Bb5Nf64.O-ONxe45.d4Nd66.Bxc6dxc67.dxe5Nf58.Qxd8+Kxd89.Rd1+Ke810.Nc3Be711.b3Nh412.Nxh4Bxh413.Be3Be714.Ne2h515.c3h4\\n16.Rd2Rh517.h3a518.Re1Be619.f4a420.Nd4Bd721.b4c522.bxc5Bxc523.Nc2Be724.Rb1b625.Nb4Be626.Nc6a327.Kh2f628.Re1f529.Nd4Bd730.Bf2Rd831.\\nRee2c532.Nc2g533.Nxa3g434.Kg1g335.Be3Ra836.Nc4Rh637.Rb2Ra638.Bc1b539.Ne3Ra440.c4bxc441.Nd5c342.Nxc3Rc443.Bd2Rc644.Kf1Be645.Rb1Rb4\\n46.Ree1Bc4+47.Kg1Rc848.Rbc1Bd349.Nd5Rb250.Bc3Rxa251.Ra1Rxa152.Bxa1c453.Nf6+Kd854.Bc3Rb855.Bd4Bb456.Rd1Rb557.Kh1Bc50-1\\nGame9-White:Black:AlphaZero\\n1.e4e52.Nf3Nc63.Bc4Bc54.d3a65.Ng5Nh66.O-Od67.a4Bg48.Nf3O-O9.h3Bh510.c3Kh811.Bxh6gxh612.Nbd2Ba713.Bd5Ne714.Bxb7Rb815.Bxa6f516.Kh1\\nNg617.exf5Nf418.d4Rxf519.Qc2Rf820.Rae1Qf621.Re3Qg722.Rg1Nd523.Bb5Bg624.Qc1Nxe325.fxe3Bf726.Rf1Bd527.Bc4Ba828.a5e429.Nh2Qg530.b4Qxe3\\n31.Ng4Qg532.Qe1h533.Ne3h434.Be6Bc635.Bc4d536.b5Bb737.Bb3Rbc838.a6Ba839.Ba4Bb640.Kg1Qg341.Qxg3hxg342.Ra1Rf243.Ndf1Re244.Nf5Rg845.\\nN1xg3Rd246.Rf1Ba547.Rf2Rxf248.Kxf2Bxc349.h4Rf850.Ke3Be151.Ke2Bxg352.Nxg3Rg853.Kf2Rg454.Bd1e3+55.Kf3Rxd456.Be2Rb457.Kxe3d4+58.Kd2\\nRb2+59.Ke1Rb360.Nh5d361.Bd1Rxb562.Nf4Ra563.g3Rxa664.Nxd3Bd565.Kd2Bf766.g4Kg767.Nf2Ra868.Be2Ra469.Bd1Rd4+70.Ke3Rb471.Nd3Rb172.Kd2\\nRb673.Ke3Re6+74.Kd2Rd675.Kc3Bg676.Nf2Rf677.Nh3Bf778.Be2Re679.Kd2Rb680.Nf2Bd581.Bd3Rb482.Bf5h683.Ke3Bf784.Nd3Rb585.Bd7Ra586.Bc6Kf8\\n87.Be4Ke788.Bf3Kd689.Nf2Bg690.h5Bb191.Nd1Bh792.Nb2Ke793.Nc4Ra694.Ne5Kf695.Nd7+Kg596.Be2Re6+97.Kf2Re70-1\\nGame10-White:Black:AlphaZero\\n1.e4e52.Nf3Nc63.Bb5Nf64.O-ONxe45.d4Nd66.Bxc6dxc67.dxe5Nf58.Qxd8+Kxd89.Nc3Be710.Rd1+Ke811.Ne4Be612.b3b613.h3Rd814.Bb2h515.Rxd8+\\nBxd816.Rd1h417.Nh2c518.c4a519.Nc3Nd420.Ng4Rh521.Kf1Bd722.f3Ne623.Nd5Bg524.Nf2Bd825.Nd3Rf526.Ne3Rg527.Bc3Rh528.Kf2Bc829.Nd5Bg530.\\nf4Bd831.Ne3Bd732.Nd5Bc833.Ne3g634.Bd2Bb735.Nd5Kd736.Nc1Kc837.Ne2Bc638.Be3Ng739.Nec3Rh840.Ne4a441.Kf3Nf542.Rd2Re843.Bf2Rg844.b4\\ncxb445.Nxb4Bb746.Nd5Re847.Kg4Nh6+48.Kf3Nf549.Kg4Nh6+50.Kf3Re651.Rd3Nf552.Rd2a353.Kg4Nh6+54.Kf3Nf555.Kg4Nh6+56.Kf3Rc657.Ke3Nf5+58.\\nKd3Re659.Re2Ne760.Ndf6Nf561.Nd5Re862.Kc3b563.Nc5Bc664.Ne4Bb765.Nc5Bc666.Ne4bxc467.Kxc4Bb768.Re1Ba6+69.Kb3Bb770.Kc4Ba871.Bc5Re672.\\nNg5Bxg573.fxg5Re874.Nf4Ng775.Bxa3Rd876.Re2Rd177.Rf2Ne678.Nxe6Bd5+79.Kb5Bxe680.Bc5Rb1+81.Kc6Rd182.Kb5Ra183.a3Re184.Bd4Rb1+85.Kc5\\nRc1+86.Kb5Bd7+87.Kb4Be688.Kb5Rb1+89.Kc5Rd190.a4Rc1+91.Kb5Kb792.Rd2Bb393.Rb2Bc4+94.Kb4Be695.Be3Re196.Bd4Rc197.Kb5Bd7+98.Kb4Ka699.\\nRb3Rc2100.g4Rd2101.Kc5Be6102.Rf3Kb7103.a5Ra2104.Bc3Ra3105.Kb5Rb3+106.Kc5Ra3107.Re3Ra2108.Be1Ra1109.Bd2Kc8110.Rd3Rd1111.Kb5Bd7+112.\\nKb4Be6113.Kc5Ra1114.Kd4Ra4+115.Kc5Ra1116.a6Rxa6117.Be1Kb7118.Bxh4Ra5+119.Kd4c5+120.Ke4Kc6121.Be1Ra2122.Rd6+Kb5123.Rd3Rh2124.Re3Rg2\\n125.Kf3Rc2126.Rc3Rh2127.Kg3Re2128.Bf2Kb4129.Rc1c4130.Re1Rc2131.Be3c3132.h4Ra2133.h5Kb3134.h6Ra8135.Rc1c2136.h7Rh8137.Rh1Kc3138.Kf4\\nKd3139.Rh2Kc3140.Ke4Kb4141.Kd3Bc4+142.Kxc2Be6143.Bc1Rc8+144.Kd3Rh8145.Ke4Ka4146.Kf4Kb3147.Rh3+Ka4148.Bb2Kb5149.Ba31-0\\nGame11-White:AlphaZeroBlack:\\n1.d4\\nf\\nbook\\ng\\nd5\\nf\\nbook\\ng\\n2.c4\\nf\\nbook\\ng\\nc6\\nf\\nbook\\ng\\n3.Nf3\\nf\\nbook\\ng\\nNf6\\nf\\nbook\\ng\\n4.Nc3booke6\\nf\\nbook\\ng\\n5.e3\\nf\\nbook\\ng\\nNbd7\\nf\\nbook\\ng\\n6.Qc2\\nf\\nbook\\ng\\nBd6\\nf\\nbook\\ng\\n7.g4\\nf\\nbook\\ng\\nBb4\\nf\\nbook\\ng\\n8.Bd2\\nf\\nbook\\ng\\nQe7\\nf\\nbook\\ng\\n9.Rg1\\nf\\nbook\\ng\\nBxc3\\nf\\nbook\\ng\\n10.Bxc3\\nf\\nbook\\ng\\nNe4\\nf\\nbook\\ng\\n11.O-O-O\\nf\\nbook\\ng\\nO-O\\nf\\nbook\\ng\\n12.Be1\\nf\\nbook\\ng\\nb613.h4Bb714.Ng5Nxg515.\\nhxg5Qxg516.f4Qe717.Kb1c518.Bd3g619.cxd5cxd420.e4Rac821.Qh2f622.f5exd523.fxg6hxg624.Rh1Qg725.Bc2Ne526.Bb3g527.Bg3Nxg428.Qh3Ne329.Rxd4\\nKf730.Bf2Rh831.Qd7+Kg632.Qxg7+Kxg733.Rxh8Rxh834.Bxe3Re835.Ra4a636.Bxb6dxe437.Rd4Bc838.Kc1e339.Rd8Rxd840.Bxd8Kg641.Bb6Bb742.Bc2+Kf7\\n43.Bxe3Ke644.Kd2Kd645.Bd31-0\\nGame12-White:AlphaZeroBlack:\\n1.d4\\nf\\nbook\\ng\\nNf6\\nf\\nbook\\ng\\n2.c4\\nf\\nbook\\ng\\ng6\\nf\\nbook\\ng\\n3.Nc3\\nf\\nbook\\ng\\nBg7\\nf\\nbook\\ng\\n4.e4bookd6\\nf\\nbook\\ng\\n5.f3\\nf\\nbook\\ng\\nO-O\\nf\\nbook\\ng\\n6.Be3\\nf\\nbook\\ng\\nc5\\nf\\nbook\\ng\\n7.Nge2\\nf\\nbook\\ng\\nNc6\\nf\\nbook\\ng\\n8.d5\\nf\\nbook\\ng\\nNe5\\nf\\nbook\\ng\\n9.Ng3\\nf\\nbook\\ng\\ne6\\nf\\nbook\\ng\\n10.Be2\\nf\\nbook\\ng\\nexd5\\nf\\nbook\\ng\\n11.cxd5\\nf\\nbook\\ng\\na612.Qd2b513.O-ORe814.Bh6Bxh615.Qxh6Qe716.Nd1Qf817.\\nQd2h518.h4Bd719.Nf2b420.Rfe1Bb521.f4Ned722.Bf3Qh623.Rad1Rab824.Nh3a525.Ng5a426.e5dxe527.f5Bc428.d6Bxa229.Bc6Bb330.Ra1Rf831.Bxa4Bxa4\\n32.Rxa4Rbe833.Ra7e434.Rc7Re535.N3xe4Nxe436.Rxe4Rxe437.Nxe4Qxd238.Nxd2Rd839.fxg6fxg640.Ne4Kf841.Kf1b342.Ke2Re843.Kd3Ne5+44.Ke3Nf745.\\nd7Re646.Rxc5Ke747.Rd5Ra648.Nc5Ra149.Rd2Rc150.Kd4Kd651.Nxb3Rc652.Na5Rc153.Rf2Nd854.Nc4+Kxd755.Ne5+Ke656.Nxg6Nc6+57.Ke3Re1+58.Kd3\\nRd1+59.Ke2Rh160.g3Rg161.Nf4+Ke762.Nxh5Ne563.Kd2Ra164.Kc3Kd665.Nf4Rc1+66.Rc2Rg167.Rg2Rc1+68.Kb3Rc869.Rd2+Ke770.Rd5Kf671.Ka2Rg872.\\nNe2Ke673.Rd4Ra8+74.Kb1Nc675.Rc4Kd676.Re4Rc877.h5Rg878.Rh4Ke779.h6Kf780.h7Rh881.Kc2Ne782.Kd3Ng683.Rh6Kg784.Rh5Nf885.b4Nxh786.Nf4\\nRe887.Rf5Nf888.Kd4Re189.b5Nd790.Kd51-0\\n28\\n', 'Game13-White:AlphaZeroBlack:\\n1.e4\\nf\\nbook\\ng\\nc6\\nf\\nbook\\ng\\n2.d4\\nf\\nbook\\ng\\nd5\\nf\\nbook\\ng\\n3.e5\\nf\\nbook\\ng\\nBf5\\nf\\nbook\\ng\\n4.Be3\\nf\\nbook\\ng\\ne6\\nf\\nbook\\ng\\n5.Nd2\\nf\\nbook\\ng\\nNd7\\nf\\nbook\\ng\\n6.Ngf3\\nf\\nbook\\ng\\nNe7\\nf\\nbook\\ng\\n7.Be2\\nf\\nbook\\ng\\nQc7\\nf\\nbook\\ng\\n8.O-O\\nf\\nbook\\ng\\nf6\\nf\\nbook\\ng\\n9.c3fxe510.Nxe5Nxe511.dxe5Qxe512.Re1Qc713.Bh5+Ng614.g4Bd315.Nb3Bc416.Nd4e517.b3Ba618.Bf4O-O-O19.Bg3Re8\\n20.a4Kb821.b4Bd622.Nf5Bc423.Qd2Ka824.Qg5Re625.Nxd6Rxd626.Bxg6Rxg627.Qxe5Qxe528.Rxe5Rxg429.f3Rg630.a5Rf631.Rae1Rff832.Kf2g633.Re7h5\\n34.Be5Rhg835.Bg7Rc836.Bd4Bb537.Kg3Bd338.Kh4Bf539.Kg5Rcd840.Bg7Rc841.R1e2Rcd842.h4Rc843.a6bxa644.Bd4Kb845.Bxa7+Ka846.Bc5Kb847.Ra2\\nBd348.Rd2Bb149.Rd1Bc250.Ba7+Ka851.Rde1Bd352.Bb6Kb853.Bd4Bf554.f4Rcd855.Ra1Bd356.Re3Bb557.Rae1Kc758.Kh6Kc859.Re6Ba460.Bc5Kb761.\\nRxg6Rxg6+62.Kxg6d463.Bxd4Bc2+64.Kxh5c565.Bxc5Kc866.Re5Rh8+67.Kg4Bd1+68.Kg3Rh769.Bd4Kd770.f5Rg7+71.Kf21-0\\nGame14-White:AlphaZeroBlack:\\n1.d4\\nf\\nbook\\ng\\nNf6\\nf\\nbook\\ng\\n2.c4\\nf\\nbook\\ng\\ne6\\nf\\nbook\\ng\\n3.Nc3\\nf\\nbook\\ng\\nBb4\\nf\\nbook\\ng\\n4.e3bookc5\\nf\\nbook\\ng\\n5.Bd3\\nf\\nbook\\ng\\nNc6\\nf\\nbook\\ng\\n6.Nf3\\nf\\nbook\\ng\\nBxc3+\\nf\\nbook\\ng\\n7.bxc3bookd6\\nf\\nbook\\ng\\n8.e4h69.e5dxe510.Nxe5cxd411.Nxc6bxc612.O-Odxc313.Ba3Qc714.Qf3Rb815.Bc5e516.Rfe1Be617.Qg3Nh518.Qe3Nf419.Bc2f620.h4Qa521.Rab1Kf7\\n22.g3Qxa223.Qe4Qxc424.Qxc6Nd325.Rxb8Rxb826.Qc7+Kg627.Bxd3+Qxd328.Qxb8Bd529.Kh2c230.Qb2a531.Qc1a432.Qe3Qxe333.fxe3Kf534.Kg1Ke435.\\nKf2Be636.Ke2Bg4+37.Kd2Bd138.Rf1f539.Rf2g640.Ba3Bg441.Kxc2Kxe342.Bc5+Ke443.Kd2g544.Bf8f445.gxf4gxf446.Ke1Be647.Rd2Kf548.Rd81-0\\nGame15-White:Black:AlphaZero\\n1.d4\\nf\\nbook\\ng\\nf5\\nf\\nbook\\ng\\n2.Nf3\\nf\\nbook\\ng\\nNf6\\nf\\nbook\\ng\\n3.g3\\nf\\nbook\\ng\\ng6\\nf\\nbook\\ng\\n4.Bg2bookBg7\\nf\\nbook\\ng\\n5.O-O\\nf\\nbook\\ng\\nO-O\\nf\\nbook\\ng\\n6.c4\\nf\\nbook\\ng\\nd6\\nf\\nbook\\ng\\n7.Nc3\\nf\\nbook\\ng\\nc6\\nf\\nbook\\ng\\n8.Rb1\\nf\\nbook\\ng\\na59.Qb3Na610.Rd1h611.Be3Rb812.Rbc1Bd713.c5+Kh714.Na4Nc715.Bd2Be616.Qc2Ncd517.b3Ra818.Be1Qe819.e3g520.Nd2Qh521.\\nBf3g422.Be2Kh823.Nc4Ne424.h4Ng525.hxg5hxg526.f3gxf327.Bf1f428.Rd2fxe329.Nxe3Nxe330.Rh2Bh331.Rxh3Qxh332.Bxh3Nxc233.Rxc2Bxd4+34.Bf2\\nBxf2+35.Kxf2Kg736.Nb6Rad837.Rc3Rh838.Be6Rh639.Re3Rf840.Nd7Rh2+41.Kf1Re242.Rxe2fxe2+43.Kxe2Rh844.Kd3Rh645.Bg4d546.Ne5e647.Nd7Kf748.\\nKe3Rh149.Bf3Re1+50.Kd2Ra151.Bd1Ke752.Ne5Kf653.Ng4+Kf554.Nh6+Ke455.Nf7g456.Nd6+Kd457.a4Ra2+58.Ke1Kxc559.Nxb7+Kb660.Nd8Rg261.Nxe6\\nRxg362.Kf2Rc363.Bxg4Rxb364.Bd1Rb465.Kf3Re40-1\\nGame16-White:Black:AlphaZero\\n1.d4\\nf\\nbook\\ng\\nNf6\\nf\\nbook\\ng\\n2.c4\\nf\\nbook\\ng\\ng6\\nf\\nbook\\ng\\n3.Nc3\\nf\\nbook\\ng\\nBg7\\nf\\nbook\\ng\\n4.e4bookd6\\nf\\nbook\\ng\\n5.f3\\nf\\nbook\\ng\\nO-O\\nf\\nbook\\ng\\n6.Be3\\nf\\nbook\\ng\\nc5\\nf\\nbook\\ng\\n7.Nge2\\nf\\nbook\\ng\\nNc6\\nf\\nbook\\ng\\n8.d5\\nf\\nbook\\ng\\nNe5\\nf\\nbook\\ng\\n9.Ng3\\nf\\nbook\\ng\\ne6\\nf\\nbook\\ng\\n10.Be2\\nf\\nbook\\ng\\nexd5\\nf\\nbook\\ng\\n11.cxd5\\nf\\nbook\\ng\\nh512.O-Oh413.Nh1h314.g3Bd715.Rc1b516.Nf2Re817.Kh1b4\\n18.Nb1Neg419.fxg4Nxe420.Nxe4Rxe421.Bf4Qe722.Bf3Bxb223.Bxd6Qxd624.Bxe4Bxc125.Qxc1Bb526.Re1Re827.Nd2c428.Nf3c329.Qf4Qc530.Ne5Re731.Qf6\\nc232.Nxg6fxg633.Qxg6+Kf834.Qf6+Kg835.d6c1=Q36.Bh7+Rxh737.Qd8+Kf738.Qe7+Kg639.Qe6+Kg540.Qg8+Kh641.Qe6+Kg742.Qe7+Kg643.Qe6+Kg544.\\nQg8+Kh645.Qe6+Kg746.Qe7+Kg847.Qd8+Be848.Qxe8+Kg749.Qe7+Kg650.Qe6+Kg551.Qg8+Kh652.Qe6+Kg553.Qg8+Kh654.Qe6+Kg755.Qd7+Kg656.Qe6+\\nKg757.Qe7+Kg858.Qd8+Kg759.Qd7+Kg660.Qe6+1/2-1/2\\nGame17-White:Black:AlphaZero\\n1.e4\\nf\\nbook\\ng\\nc5\\nf\\nbook\\ng\\n2.Nf3\\nf\\nbook\\ng\\nd6\\nf\\nbook\\ng\\n3.d4\\nf\\nbook\\ng\\ncxd4\\nf\\nbook\\ng\\n4.Nxd4\\nf\\nbook\\ng\\nNf6\\nf\\nbook\\ng\\n5.Nc3\\nf\\nbook\\ng\\na6\\nf\\nbook\\ng\\n6.Bg5\\nf\\nbook\\ng\\nNbd7\\nf\\nbook\\ng\\n7.f4booke6\\nf\\nbook\\ng\\n8.Qe2\\nf\\nbook\\ng\\nBe7\\nf\\nbook\\ng\\n9.O-O-O\\nf\\nbook\\ng\\nQc7\\nf\\nbook\\ng\\n10.g4\\nf\\nbook\\ng\\nb5\\nf\\nbook\\ng\\n11.a3\\nf\\nbook\\ng\\nRb812.Bg2b413.axb4h614.Bh4Rxb415.Be1Qb616.Bf2Qb717.\\nRhg1Qc718.Bf3Nb619.Na2Ra420.Kb1e521.fxe5dxe522.Nb3Nc423.h4h524.gxh5Be625.Rxg7a526.Be1Rxa227.Kxa2a428.Nc1Na3+29.Ka1Nxc2+30.Kb1Nxe1\\n31.Qxe1a332.b3a2+33.Kxa2Nd534.Rxd5Bxd535.Kb1Bb736.Rg2Qd637.Qc3Kf838.Nd3Rg839.Rxg8+Kxg840.Kc2Bf841.b4Qa642.Kb3Bc643.Nc5Qf144.Kc2\\nBb545.Kb3Bh646.Ka3Bc1+47.Kb3Bf448.Ka3Bh649.Nb3Bd750.Nc5Bb551.Nb3Bd752.Nc5Bc1+53.Kb3Bb554.Na4Bh655.Qc8+Bf856.Qc3Bh657.Qc8+Bf858.\\nQc3Bd759.Nc5Bb560.Kb2Bh661.Nb3Bf462.Qc8+Kg763.h6+Bxh664.Qg4+Kh765.Qf5+Kg866.Qg4+Kh767.Qf5+Kg868.Qg4+Kh71/2-1/2\\nGame18-White:Black:AlphaZero\\n1.e4\\nf\\nbook\\ng\\ne5\\nf\\nbook\\ng\\n2.Nf3\\nf\\nbook\\ng\\nNc6\\nf\\nbook\\ng\\n3.Bb5\\nf\\nbook\\ng\\na6\\nf\\nbook\\ng\\n4.Bxc6\\nf\\nbook\\ng\\ndxc6\\nf\\nbook\\ng\\n5.O-O\\nf\\nbook\\ng\\nf6\\nf\\nbook\\ng\\n6.d4\\nf\\nbook\\ng\\nBg4\\nf\\nbook\\ng\\n7.c3\\nf\\nbook\\ng\\nBd6\\nf\\nbook\\ng\\n8.Be3\\nf\\nbook\\ng\\nQe7\\nf\\nbook\\ng\\n9.Nbd2\\nf\\nbook\\ng\\nO-O-O\\nf\\nbook\\ng\\n10.dxe5fxe511.h3Bd712.b4Nf613.Qb3g514.Bxg5Rdg815.Kh1Rg616.Rg1Be617.c4Rhg818.Bh4\\nQf819.Qe3c520.Rac1b621.b5Nh522.bxa6Qg723.g3Bxh324.a4Kb825.a5Bc826.Rg2Ka727.Rh2Bg428.Qd3Qf729.Rc3bxa530.Rb3a431.Rb7+Kxa632.Rb1Qe833.\\nBg5Nf634.Bxf6Rxf635.Qc3Bf836.Rb5Rb637.Qa3Bd738.Qxa4+Kb739.Rxb6+cxb640.Qc2h541.Kg2Bg742.Rh1Qf743.Nh4Bc644.Ndf3Rd845.Nf5Bf646.Ne3Qg6\\n47.Nd5Rxd548.cxd5Bxd549.Nd2Bc650.Qa2Bg551.f3Bf452.Nf1b553.Qb2c454.Kf2Bg555.Qxe5Bd856.Ke2h457.g4Qg558.Qxg5Bxg559.Ne3Kb660.Rd1Kc561.\\nNd5b462.f4Bh663.g5Bf864.f5c365.f6Be866.Kd3Bb5+67.Ke3Kc468.Nb6+Kb369.g6c270.Re1Be871.g7Bc5+72.Kd2Bf773.e5Bf274.Re2Bg375.Re4h376.e6\\nh277.Re3+Kb278.Nc4+Kb179.Rb3+Ka180.exf7h1=Q81.Kxc2Qe4+82.Kd2Bf4+83.Ne3Qd5+84.Ke2Qh5+85.Kd3Qxf786.Rxb4Bg587.Ng4Ka288.Rd4Qe889.Re4\\nQd7+90.Ke2Qd591.Kf3Ka192.Ne3Qf793.Ng4Qg694.Ra4+Kb195.Ke2Qe8+96.Kf2Qe697.Kf1Qf5+98.Ke1Bh4+99.Ke2Qc2+100.Kf3Qd1+101.Ke3Qd5102.Kf4\\nKb2103.Ke3Kc2104.Kf4Bg5+105.Kg3Kb2106.Kh2Qd2+107.Kg1Qd1+108.Kf2Qc2+109.Ke1Qg6110.Ne5Qe8111.Re4Qg8112.Ng4Kc3113.Ke2Qa2+114.Kf3Qd5\\n115.Ne3Qf7116.Re7Qxf6+117.Kg4Qg6118.Nd5+Kd2119.Nf4Bxf4+120.Kxf4Kd1121.Kf3Qg5122.Rd7+Kc1123.Ra7Kb2124.Rb7+Kc3125.Ra7Kb3126.Rc7Qf5+\\n127.Kg3Qe6128.Ra7Qg6+129.Kf3Kb2130.Rb7+Kc2131.Ra7Qf5+132.Kg2Qg4+133.Kf2Kb3134.Re7Kb2135.Re2+Kc1136.Re1+Kd2137.Re7Qg5138.Ra7Kc2139.\\nRc7+Kd3140.Kf3Qf5+141.Kg3Qg6+142.Kf3Qe4+143.Kg3Qe6144.Ra7Qg6+145.Kf3Qf5+146.Kg3Qg5+147.Kf3Kc3148.Rc7+Kb3149.Ra7Qg6150.Rb7+Kc3151.\\nRa7Qf5+152.Ke3Qg4153.Re7Kc2154.Rb7Qg5+155.Kf3Kc3156.Ra7Qf5+157.Ke3Qg4158.Re7Kc2159.Rb7Qe6+160.Kf4Kd2161.Rd7+Ke2162.Re7Qxe7163.g8=Q\\nQe3+164.Kf5Qd3+165.Kf4Qf3+166.Ke5Qc3+167.Ke4Qc2+168.Ke5Qc3+169.Ke4Qc2+170.Ke5Qb2+171.Ke4Qb1+172.Ke5Qa1+173.Ke4Qb1+174.Ke5Qb2+175.\\nKe4Qb4+176.Kf5Qc5+177.Ke4Qe7+178.Kf5Qc5+179.Ke4Qe3+180.Kf5Qd3+181.Kf4Qd4+182.Kf5Qf2+183.Ke4Qf3+184.Ke5Qe3+185.Kf6Qf4+186.Kg7Qe5+187.\\nKg6Qg3+188.Kh7Qh4+189.Kg6Qg3+190.Kf7Qc7+191.Kf6Qf4+192.Kg7Qd4+193.Kg6Qe4+194.Kf7Qf5+195.Ke8Qb5+196.Ke7Qc5+197.Kf6Qc3+198.Kf5Qf3+\\n199.Kg6Qg4+200.Kh7Qe4+201.Kh6Qh4+202.Kg7Qd4+203.Kg6Qg4+204.Kh7Qd7+205.Kg6Qc6+206.Kf5Qb5+207.Ke4Qa4+208.Kf5Qc2+209.Kf4Qc1+210.Kf5\\nQf1+211.Ke4Qf3+212.Ke51/2-1/2\\nGame19-White:Black:AlphaZero\\n1.e4\\nf\\nbook\\ng\\ne5\\nf\\nbook\\ng\\n2.Nf3\\nf\\nbook\\ng\\nNc6\\nf\\nbook\\ng\\n3.Bb5\\nf\\nbook\\ng\\nf5\\nf\\nbook\\ng\\n4.Nc3fxe45.Nxe4Nf66.Nxf6+Qxf67.Qe2Be78.Bxc6bxc69.Nxe5Bb710.O-OO-O-O11.d3\\nRde812.Nc4h513.Qe3h414.Qh3Kb815.Bd2d516.Bc3d417.Bd2Bc818.Qf3Qxf319.gxf3Be620.f4h321.Ne5Bf622.Nxc6+Kc823.Rfe1Bd524.Rxe8+Rxe825.Ne5\\nBxe526.Re1Kd727.fxe5Re628.c4dxc329.Bxc3Rg6+30.Kf1Bxa231.Re3Be632.Rg3Rxg333.fxg3Bg434.e6+Kxe635.Bxg7Kf536.b4c637.Bd4a638.Kf2Bd139.Bc5\\nKg440.Ke3Ba441.Bd4Bc242.Ke4Ba443.Bc5Bb544.Be3Ba445.d4Bd146.Bf4Ba447.Ke5Bb548.Kf6Ba449.Ke6Bb550.Kd6Kh551.Kc5Ba452.Kb6Bb553.Be5Kg5\\n54.Bh8Kg655.Ka5Kg556.Bg7Kg657.Bf8Kh558.Be7Bf159.Kb6Bb560.Bd8Kg461.Bc7Kg562.Kc5Ba463.Kd6Bb564.Bd8+Kh565.Kc5Kg466.Bc7Kh567.Bb6Ba4\\n68.Bd8Kg469.Bf6Bb570.Kb6Kh571.Bg7Kg572.Ka7Kh573.Bf6Kg474.Be5Kh575.Kb8Kg576.Kb7Kh577.Ka7Kg578.Bh8Kh579.Kb8Kg480.Kc7Kg581.Kd6Kh5\\n82.Bg7Ba483.Bf6Bb584.Ke7Kg485.Bh8Kg586.Ke6Kg487.Be5Ba488.Kf6Bb589.Ke7Kg590.Bc7Kg491.Kd8Kg592.Kc8Kh593.Bd6Kg494.Kb7Kf395.g4Kxg4\\n96.Kb6Kf397.Be5Ke498.Kc5Ba499.Kc4Bb5+100.Kc5Ba4101.Bg3Bb5102.Bd6Ba4103.Bc7Bb5104.Bd6Ba4105.Kc4Bb5+106.Kc51/2-1/2\\nGame20-White:Black:AlphaZero\\n1.d4\\nf\\nbook\\ng\\nd5\\nf\\nbook\\ng\\n2.c4\\nf\\nbook\\ng\\nNc6\\nf\\nbook\\ng\\n3.Nf3\\nf\\nbook\\ng\\nBg4\\nf\\nbook\\ng\\n4.cxd5\\nf\\nbook\\ng\\nBxf3\\nf\\nbook\\ng\\n5.gxf3\\nf\\nbook\\ng\\nQxd5\\nf\\nbook\\ng\\n6.e3\\nf\\nbook\\ng\\ne5\\nf\\nbook\\ng\\n7.Nc3book\\nBb4\\nf\\nbook\\ng\\n8.Bd2\\nf\\nbook\\ng\\nBxc3\\nf\\nbook\\ng\\n9.bxc3\\nf\\nbook\\ng\\nQd6\\nf\\nbook\\ng\\n10.Qb3Nge711.Qxb7O-O12.Qa6Rfd813.Rd1Rab814.h4h515.Be2Rb616.Qc4Rdb817.Qa4Qg618.\\nKf1Rb119.e4exd420.cxd4Qd621.d5Ne522.f4N5g623.Rh3c624.f5Ne525.Rxb1Rxb1+26.Kg2Nxf527.Bxh5Qc528.Bd1Rb229.Rc3Nxh4+30.Kf1Qb631.Be3Qd832.\\nBc1Rb633.Qxa7cxd534.exd5Rb535.d6Qxd636.Bc2g537.Ba3Qd838.Be7Qe839.Bf6Rb840.a4Ng441.Qe7Nh2+42.Ke2Ng443.Bxg5Qxe7+44.Bxe7Re845.Rc7Nf6\\n46.Kd3Nd547.Rc4Nf348.Bd6Rd849.Rg4+Kh850.Ke2Nf651.Rc4Ng1+52.Kf1Rxd653.Kxg1Ra654.Rc5Nd755.Rd5Nf656.Rf5Rc657.Bd3Rc1+58.Kg2Kg759.a5\\nRc360.Rf3Rc161.a6Ne862.Re3Nc763.Bf1Ra164.Re7Nxa665.Ra7Rxf166.Kxf1Nc567.Ke2Kg668.Ke3f669.Rc7Ne670.Rc6Ng771.Kf4Nf572.Ke4Ne773.Rc5Kg7\\n74.f4Kf775.f5Kg776.Kf4Kg877.Kg41-0\\nTableS6:GamesplayedbyAlphaZeroagainstselectedbyGMMatthewSadler.The\\n10gamesarefromtheinitialboardposition,theremaining10gamesarefrom2016TCEC\\nworldchampionshipstartpositions.\\n29\\n', 'Game1-Black:AlphaZeroWhite:Elmo\\n+2726FU-8384FU+2625FU-8485FU+9796FU-4132KI+3938GI-9394FU+6978KI-7172GI+3736FU-3334FU+2524FU-2324FU+2824HI-8586FU+8786FU-8286HI+5968OU\\n-8685HI+7776FU-2288UM+7988GI-0033KA+2421RY-3388UM+8977KE-8877UM+6877OU-8589RY+0024KE-0085KE+7766OU-0041GI+7868KI-8979RY+6858KI-0027FU\\n+0083FU-2728TO+2432NK-3132GI+2128RY-0054KE+6656OU-7976RY+0066KI-5466KE+6766FU-8577NK+0022KA-7283GI+4746FU-8374GI+0045KE-6152KI+5647OU-\\n7767NK+0072FU-5161OU+0082KA-6172OU+8291UM-4344FU+4533NK-4445FU+0082FU-6758NK+4958KI-4546FU+4737OU-7678RY+0068KE-7869RY+0059KY-0027FU\\n+2827RY-0047KI+3847GI-4647TO+3747OU-8193KE+2725RY-0046FU+4746OU-0045FU+2545RY-0054GI+4515RY-0071KI+0084KI-6989RY+6876KE-1314FU+1525RY\\n-0024FU+2534RY-7475GI+8281TO-7584GI+8171TO-7283OU+0075FU-8475GI+0065KI-0055KI+6555KI-5455GI+4637OU-0044FU+0065KI-7576GI+6575KI-0045KE\\n+3445RY-4445FU+3332NK-5546GI+3728OU-0038KI+2838OU-0028HI+3828OU-4637NG+2818OU-3728NG+1828OU-9495FU+9182UM-8382OU+0081HI-8292OU+0091KI\\n%TORYO\\nGame2-Black:AlphaZeroWhite:Elmo\\n+2726FU-8384FU+2625FU-8485FU+2524FU-2324FU+6978KI-4132KI+2824HI-0023FU+2426HI-5142OU+7776FU-3334FU+8877KA-2277UM+7877KI-6364FU+5968OU\\n-7172GI+9796FU-7374FU+2628HI-8173KE+4958KI-8281HI+7988GI-3122GI+3948GI-2233GI+4746FU-1314FU+3736FU-7263GI+4847GI-9394FU+1716FU-4252OU\\n+6766FU-6162KI+4756GI-5354FU+7778KI-8586FU+8786FU-8186HI+8887GI-8681HI+0086FU-0022KA+2937KE-3344GI+5847KI-0088FU+7888KI-4455GI+5655GI-\\n2255KA+8977KE-5566KA+0067FU-6622KA+6878OU-1415FU+1615FU-2244KA+3745KE-2133KE+4533NK-3233KI+0045KE-3332KI+5756FU-9495FU+5655FU-9596FU\\n+9996KY-0095FU+9695KY-9195KY+0096FU-7475FU+7675FU-0076FU+8776GI-0084KE+8887KI-8476KE+8776KI-0098GI+0079KE-9596KY+7574FU-6374GI+5554FU\\n-0075FU+7666KI-5241OU+5453TO-6253KI+4553NK-4453KA+0054FU-5344KA+0053GI-0052FU+5344NG-4344FU+0021KA-0042GI+0092KA-0024KY+0025FU-8184HI\\n+5453TO-4253GI+0054FU-5342GI+2524FU-2324FU+5453TO-4253GI+0055KY-0054KE+0023FU-7463GI+5554KY-6354GI+0055FU-5463GI+0022KI-3233KI+0043KE\\n-5362GI+2231KI-4142OU+2322TO-3343KI+2132UM-4251OU+3243UM-8486HI+0087FU-8682HI+0093KI-8292HI+9392KI-5161OU+0091HI-0071KY+9282KI-0081FU\\n+9181RY-0072GI+8191RY-7576FU+6676KI-0074KA+4757KI-0081FU+0075FU-7483KA+8272KI-8372KA+0042GI-7283KA+5554FU-6172OU+4253GI-5253FU+5453TO\\n-6253GI+4353UM-0062GI+5343UM-0052KI+0092GI-5243KI+9283NG-7261OU+0021KA-4353KI+0054FU-5352KI+9181RY-0072KA+8182RY-7283KA+8283RY-0072GI\\n+8393RY-0086FU+0091KA-8687TO+7987KE-9697NY+7868OU-9887GI+7666KI-8788GI+5747KI-8877GI+6877OU-0065KE+7768OU-0053FU+5453TO-5253KI+0054FU\\n-6354GI+0042GI-0057FU+3141KI-0077FU+9182UM-7778TO+6878OU-5363KI+0052FU-6152OU+2132UM-9787NY+7887OU-6577NK+8777OU-7365KE+7788OU-6577NK\\n+8877OU-0065KE+7786OU-0085FU+8696OU-0095FU+9685OU-0073KE+8594OU-3435FU+8291UM%TORYO\\nGame3-Black:AlphaZeroWhite:Elmo\\n+6978KI-3334FU+7776FU-8384FU+2726FU-4132KI+2625FU-8485FU+2524FU-2324FU+2824HI-8586FU+8786FU-8286HI+2434HI-2233KA+5958OU-5152OU+3736FU\\n-8676HI+8877KA-0026FU+0028FU-2627TO+2827FU-3377UM+7877KI-7674HI+3474HI-7374FU+0028KA-0073KA+0083HI-7172GI+8388RY-7328UM+3928GI-0073KA\\n+0046KA-0087FU+7787KI-7346KA+4746FU-0055KA+8777KI-5546KA+4939KI-0026FU+2726FU-0027FU+2837GI-4637UM+2937KE-2728TO+3928KI-0039HI+1918KY\\n-3919RY+5847OU-1949RY+4756OU-8173KE+6766FU-0058GI+0038KA-4939RY+2829KI-3948RY+0076KA-5859GI+8848RY-5948GI+5647OU-0069HI+4748OU-6979RY\\n+0044FU-4344FU+0083FU-7989RY+8382TO-8982RY+3816KA-0034FU+0086FU-5354FU+1634KA-0043GI+3416KA-0034FU+0045FU-1314FU+4544FU-4344GI+1634KA\\n-0043FU+2938KI-8284RY+7667KA-8475RY+7776KI-7555RY+0047FU-4433GI+3423UM-3223KI+6723UM-0034KA+2334UM-3334GI+0067KA-0013KA+0058GI-0045KE\\n+3745KE-3445GI+0025KE-1322KA+0023HI-5262OU+2343RY-4536GI+0037FU-0042FU+4323RY-3645GI+0041KI-0034KE+3827KI-3426KE+2726KI-2244KA+0027FU\\n-0022FU+2324RY-3132GI+2635KI-4435KA+2435RY-3241GI+6745KA-0044KI+3531RY-5545RY+3141RY-0051KI+4121RY-4525RY+0036GI-2523RY+0026KA-2326RY\\n+2726FU-0024KE+3625GI-5455FU+2131RY-0054KA+0065KE-7365KE+7665KI-5465KA+6665FU-5556FU+0095KA-0073KE+0085KE-9394FU+8573NK-7273GI+0071GI\\n-6171KI+9573UM-6273OU+3151RY-5657TO+5857GI-0056KE+5756GI-0084KA+0057FU-0062GI+0075KE-0049KI+4838OU-4948KI+3848OU-2436KE+3736FU-0059KA\\n+4858OU-5948UM+5869OU-4859UM+6979OU-5969UM+7989OU-0088FU+8998OU-6987UM+9887OU-8475KA+0085KE%TORYO\\nGame4-Black:AlphaZeroWhite:Elmo\\n+2726FU-8384FU+2625FU-8485FU+6978KI-4132KI+9796FU-7172GI+3938GI-1314FU+3736FU-8586FU+8786FU-8286HI+5958OU-5162OU+2937KE-8636HI+7776FU\\n-6271OU+8866KA-3634HI+8977KE-0083FU+7968GI-3454HI+7879KI-7182OU+2826HI-3142GI+9695FU-2213KA+2636HI-1322KA+3656HI-5474HI+1716FU-2231KA\\n+5655HI-4251GI+5575HI-7434HI+1615FU-1415FU+2524FU-3424HI+7785KE-8384FU+8593NK-8293OU+7525HI-2434HI+9594FU-9382OU+9493TO-9193KY+0094FU\\n-9394KY+9994KY-0093FU+9493KY-8293OU+0085FU-0064KY+6677KA-8485FU+0089KY-7374FU+2585HI-0084FU+8584HI-0083FU+8485HI-0094FU+0095FU-9382OU\\n+6766FU-1516FU+9594FU-1617TO+6665FU-0073KE+8595HI-7365KE+9493TO-8193KE+0094FU-6577NK+9493TO-8273OU+0065FU-7768NK+7968KI-6465KY+9565HI\\n-8384FU+6595HI-0094FU+9394TO-1727TO+9484TO-7362OU+8483TO-0084FU+8372TO-6172KI+0065KE-0094FU+9594HI-0093FU+9493RY-6252OU+0073KY-7262KI\\n+0071GI-0061GI+7162NG-6162GI+7372NY-0071GI+7271NY-6271GI+9392RY-5241OU+0045KE-0062KA+0061KI-0064KY+0072GI-7172GI+9272RY-0071GI+6171KI\\n-6465KY+0066FU-2738TO+4938KI-0026KE+3828KI-1118NY+7161KI-0052GI+0024FU-1828NY+0071GI-5261GI+7261RY-0052KI+2423TO-3223KI+0012GI-0022KI\\n+1223NG-3437RY+0032FU-3738RY+0048GI-2223KI+7162NG-0049GI+5869OU-4958NG+6858KI-3849RY+0059KA-0077KE+6978OU-4958RY+7887OU-2819NY+0068KI\\n-4132OU+6858KI-0041KI+6251NG-4151KI+6191RY-7769NK+5977KA-6979NK+0024FU-2324KI+0025FU-2434KI+0012HI-0022FU+2524FU-3424KI+1211RY-4344FU\\n+0035FU-0095FU+7795KA-0094FU+9194RY-0093FU+9493RY-7989NK+0012GI-3243OU+4533NK-2133KE+1131RY-5142KI+9584KA-2435KI+0061KA-0041GI+0051GI\\n-0081KY+0082FU-8988NK+8796OU-0083FU+5142GI-4334OU+0036KI-3536KI+6152UM-4152GI+3133RY-3425OU+0017KE-2516OU+3336RY-0094KY+0095FU-0069KA\\n+9685OU-6996UM+8596OU-0085KI+9697OU-8898NK+9787OU-9897NK+8778OU-9787NK+7879OU-8778NK+7978OU-0086KE+7888OU-8678NK+8878OU-2223FU\\n+0027KI-1615OU+3625RY%TORYO\\nGame5-Black:AlphaZeroWhite:Elmo\\n+6978KI-3334FU+7776FU-8384FU+2726FU-4132KI+2625FU-8485FU+2524FU-2324FU+2824HI-8586FU+8786FU-8286HI+2434HI-2233KA+5958OU-5141OU+3436HI\\n-8684HI+3626HI-3122GI+3736FU-0086FU+8833UM-2133KE+0088FU-0025FU+2628HI-4152OU+3938GI-5262OU+2937KE-7172GI+2829HI-8434HI+0082KA-3436HI\\n+8291UM-2223GI+9192UM-2526FU+4948KI-0074KA+9282UM-3634HI+0036FU-3436HI+7877KI-3634HI+0036FU-3436HI+7786KI-3634HI+0036FU-3436HI+8675KI\\n-7483KA+0087KY-8394KA+8292UM-0084FU+9796FU-3635HI+9695FU-9483KA+9282UM-6171KI+8271UM-6271OU+8784KY-0036FU+0046KI-3637TO+3837GI-3534HI\\n+8483NY-7283GI+3726GI-7374FU+2635GI-3414HI+7565KI-0034FU+3526GI-0025FU+0024FU-2324GI+0041KA-0023KA+9594FU-9394FU+2637GI-7162OU+0092FU\\n-8173KE+6555KI-2435GI+9291TO-8372GI+9192TO-0081FU+1716FU-0054KY+5554KI-5354FU+9281TO-7281GI+7675FU-0042KI+4132UM-2332KA+7574FU-7365KE\\n+4656KI-0053KE+0036FU-5455FU+5666KI-3345KE+3635FU-4537NK+4837KI-4344FU+3746KI-5345KE+7473TO-6273OU+7968GI-4557NK+6857GI-6557NK+5857OU\\n-0056GI+4656KI-5556FU+6656KI-0065GI+0046KI-0045KI+0074FU-7362OU+0073GI-6251OU+0055KY-4555KI+5655KI-0056FU+5758OU-0053KY+0062GI-5141OU\\n+0033KE-4131OU+6253GI-4253KI+0049KE-0057GI+4957KE-5657TO+5857OU-0056FU+5748OU-0045KE+0049KE-5354KI+3321NK-3121OU+0023FU-0022KE+0033KI\\n-4557NK+4957KE-5657TO+4857OU-0056FU+4656KI-6556GI+5556KI-0075KA+0066KY-0065KE+5665KI-0056FU+5768OU-5657TO+6857OU-3223KA+0043GI%TORYO\\nGame6-Black:AlphaZeroWhite:Elmo\\n+6978KI-3334FU+7776FU-8384FU+2726FU-4132KI+2625FU-8485FU+2524FU-2324FU+2824HI-8586FU+8786FU-8286HI+2434HI-2233KA+5958OU-3142GI+3736FU\\n-5141OU+2937KE-0022FU+3938GI-6151KI+3435HI-8682HI+3525HI-0086FU+0085FU-9394FU+8877KA-8193KE+7988GI-9385KE+7786KA-0087FU+7887KI-9495FU\\n+8675KA-7374FU+0083FU-8283HI+0084FU-8381HI+7566KA-3366KA+6766FU-8184HI+0073KA-8483HI+7391UM-0034KA+9192UM-8384HI+9293UM-8481HI+9392UM\\n-8184HI+0086FU-3489UM+4959KI-9596FU+5968KI-8597NK+9997KY-9697TO+8897GI-8998UM+9293UM-9887UM+9384UM-0083FU+8483UM-0081FU+2529HI-0044KE\\n+0025KY-8776UM+6867KI-0048KI+5868OU-4838KI+2926HI-7687UM+2522NY-0024FU+2232NY-4132OU+0088KI-8754UM+0046KE-3837KI+4654KE-5354FU+0023FU\\n-0033GI+2629HI-0055KE+6777KI-3223OU+0022FU-2322OU+6878OU-0095FU+0025FU-3738KI+2999HI-2232OU+0076FU-7475FU+7675FU-0076FU+7776KI-0096KY\\n+9796GI-9596FU+2524FU-0022FU+0026KY-0064KE+7665KI-0095KY+8394UM-0067GI+7889OU-9697TO+9495UM-9788TO+8988OU-7162GI+0079KY-6476KE+8887OU\\n-0088KI+8796OU-8899KI+0045KA-3241OU+0072HI-4253GI+7574FU-4436KE+2423TO-0094FU+9594UM-9998KI+0034FU-0097HI+9685OU-3344GI+3433TO-4433GI\\n+0095FU-3342GI+2322TO-0071FU+7292RY-8182FU+4523UM-4152OU+2232TO-5547KE+9484UM-7668NK+9282RY-0081FU+8292RY-6879NK+7473TO-0082KY+7382TO\\n-8182FU+0075KY-9777RY+0074FU-6776GI+8594OU-7172FU+7473TO-7273FU+0074FU-7665GI+6665FU-0093FU+9493OU-0083KI+8483UM-8283FU+0071GI-0084KA\\n+9382OU-0022FU+2334UM-7374FU+8281OU-7775RY+0044FU-7565RY+3242TO-5342GI+4443TO-4243GI+0044KI-4334GI+0053GI-5241OU+4434KI-0042FU+0043GI\\n-6253GI+2622NY-0031KY+0032FU-0072KA+9272RY-0092GI+8191OU-8473KA+0082KA-7382KA+7182NG-5162KI+7262RY-1314FU+3231TO%TORYO\\n30\\n', 'Game7-Black:ElmoWhite:AlphaZero\\n+7776FU-8384FU+8877KA-3334FU+7978GI-2277UM+7877GI-4132KI+3736FU-9394FU+5968OU-7162GI+2726FU-3142GI+2625FU-4233GI+3938GI-8485FU+2937KE\\n-6152KI+9796FU-7374FU+4746FU-6364FU+6978KI-5142OU+1716FU-1314FU+3635FU-3435FU+3745KE-3322GI+1615FU-4344FU+1514FU-0012FU+0033FU-3231KI\\n+2524FU-2324FU+2824HI-4445FU+2429HI-0023FU+0034KA-5243KI+3423UM-2223GI+2923RY-4333KI+2326RY-0023FU+0034FU-3324KI+4645FU-6263GI+0025GI\\n-2425KI+2625RY-3132KI+4544FU-6354GI+0024FU-2324FU+2535RY-4251OU+0043KI-8586FU+8786FU-5443GI+4443TO-3243KI+0044FU-4342KI+3524RY-0032GI\\n+2426RY-0025FU+2625RY-0046KA+0043GI-0024FU+2545RY-0055KI+4546RY-5546KI+0071KA-8292HI+4332NG-4232KI+7153UM-4657KI+6879OU-0052FU+5354UM-\\n0065KE+0069GI-0046KA+5436UM-4619UM+0058FU-0097KY+5857FU-9799NY+6766FU-6557NK+0058FU-9989NY+7989OU-0097KY+7888KI-5767NK+0098KY-0065KE\\n+6665FU-0087FU+8887KI-9798NY+8998OU-0097KY+8797KI-6777NK+0061KI-5141OU+6151KI-4151OU+0089KY-0088GI+8988KY-0079HI+0063KE-5162OU+0051GI\\n-6273OU+0089KY-0078GI+6978GI-0099KI+9899OU-7778NK+0084GI-7384OU+8685FU-8473OU+0083KI-7383OU+8584FU-8372OU+8483TO-7261OU+8372TO-9272HI\\n+6371NK-6151OU+7161NK-5142OU+3433TO-3233KI+4443TO-3343KI+9998OU-0077KI+9787KI-0086FU+9897OU-8687TO%TORYO\\nGame8-Black:ElmoWhite:AlphaZero\\n+7776FU-8384FU+8877KA-3334FU+7978GI-2277KA+7877GI-8485FU+3938GI-4132KI+2726FU-3142GI+6978KI-7162GI+4746FU-1314FU+9796FU-9394FU+3736FU\\n-4233GI+5968OU-6364FU+2937KE-1415FU+3847GI-6152KI+4938KI-7374FU+1918KY-6263GI+2829HI-8173KE+2919HI-3344GI+1716FU-3435FU+1615FU-3536FU\\n+4736GI-7475FU+7675FU-0076FU+7776GI-0054KA+4645FU-5476KA+4544FU-4344FU+0074GI-6372GI+7473NG-7273GI+7574FU-7362GI+0073KA-8281HI+7364UM\\n-8586FU+8786FU-6263GI+6455UM-0075GI+7473TO-6364GI+5544UM-6473GI+4411UM-0066FU+0077KY-7665KA+0047FU-6667TO+6867OU-0066FU+6758OU-0076FU\\n+1121UM-6667TO+7867KI-8186HI+5848OU-8688RY+0068FU-0066FU+6756KI-8868RY+4839OU-6554KA+0045KE-7677TO+3928OU-0035FU+3635GI-6667TO+5646KI\\n-6757TO+0044KE-0036FU+0039FU-3637TO+2837OU-0043GI+0055FU-5465KA+8977KE-6877RY+4452NK-5152OU+5554FU-5747TO+3847KI-0055KE+0048FU-0034KY\\n+3727OU-5547NK+4847FU-3435KY+5453TO-5261OU+5363TO-0072KI+0057FU-7757RY+4553KE-6171OU+0036KE-0033KE+0058FU-5746RY+4746FU-7263KI+0041HI\\n-0051FU+0084FU-3536KY+4151RY-7182OU+0083KI-6583KA+8483TO-8283OU+5181RY-8374OU+0083KA-7464OU+2736OU-0035FU+3647OU-0036KI+4757OU-3345KE\\n+4645FU-0046GI%TORYO\\nGame9-Black:ElmoWhite:AlphaZero\\n+7776FU-8384FU+8877KA-3334FU+7978GI-4132KI+2726FU-2277UM+7877GI-8485FU+3938GI-3142GI+2625FU-4233GI+3736FU-7162GI+6978KI-9394FU+3837GI\\n-6364FU+3746GI-6263GI+5968OU-6354GI+9796FU-4344FU+3635FU-4445FU+3534FU-4546FU+3433TO-4647TO+3332TO-0046KA+0037FU-4657UM+6869OU-0048FU\\n+0068GI-4849TO+6857GI-4757TO+6979OU-4959TO+0035KA-5162OU+3242TO-8586FU+0052KI-6152KI+4252TO-6252OU+8786FU-0087FU+7887KI-0045KI+0055FU\\n-5443GI+3557KA-5958TO+2858HI-0047KI+5828HI-4757KI+0078KI-0047KA+7988OU-0069GI+7879KI-0038FU+0044FU-4544KI+0036KA-4736UM+3736FU-5758KI\\n+0045FU-4455KI+2838HI-0046KA+0057FU-4657UM+7768GI-5746UM+0057FU-0048FU+0022KA-0085FU+8685FU-0074GI+8997KE-9495FU+9695FU-8193KE+4544FU\\n-4354GI+2211UM-9385KE+0086FU-8597NK+8897OU-0085FU+4443TO-5443GI+0089KY-8586FU+8786KI-0085FU+8696KI-0094FU+9594FU-0083KE+0044FU-4334GI\\n+7969KI-5869KI+0093GI-8281HI+0082FU-8171HI+4443TO-3443GI+0066KE-0095FU+9695KI-8395KE+0044FU-4334GI+6877GI-0086KI+7786GI-8586FU+0062KI-5262OU\\n+6674KE-7374FU+9786OU-0087KI+8987KY-9587NK+8687OU-0085KY+0086KE-0073KE+0084KI-5565KI+0077GI-4655UM+6766FU-0068GI%TORYO\\nGame10-Black:ElmoWhite:AlphaZero\\n+7776FU-8384FU+8877KA-3334FU+7978GI-9394FU+3736FU-8485FU+5968OU-4132KI+3938GI-2233KA+7733UM-3233KI+7877GI-9495FU+2726FU-6152KI+2625FU\\n-3122GI+3837GI-6364FU+3746GI-7162GI+2937KE-4344FU+4938KI-6263GI+4655GI-5162OU+0046KA-6465FU+5564GI-6364GI+4664KA-0054KA+2826HI-5263KI\\n+6446KA-4445FU+4655KA-0064GI+0056GI-6455GI+5655GI-5432KA+3745KE-3343KI+3635FU-8284HI+0075GI-8494HI+9796FU-9596FU+0095FU-9492HI+9996KY\\n-6252OU+7564GI-6364KI+5564GI-9262HI+0063KI-6263HI+6463GI-5263OU+2524FU-2324FU+3534FU-0044KA+2624HI-2223GI+2429HI-0028FU+2928HI-8586FU\\n+3433TO-2133KE+4533NK-4333KI+0034FU-2334GI+2822RY-8687TO+0061HI-0062GI+6181RY-8777TO+8977KE-6566FU+2232RY-3332KI+0041KA-0052KE+0075KE\\n-6364OU+8184RY-7374FU+0079KE-3242KI+4152UM-4252KI+0056KE-6455OU+7583KE-0098HI+0088FU-5263KI+8391NK-0097KA+8487RY-9899RY+8785RY-7475FU\\n+5644KE-0086GI+6858OU-9988RY+0068KY-8877RY+0099KA-0088FU+4432NK-0036KE+0037FU-0028KI+3828KI-3628NK+5756FU-5556OU+0057KI-5645OU+3233NK\\n-2838NK+4746FU-4555OU+0056FU-5544OU+3334NK-4434OU+8584RY-0054KE+0049GI-3837NK+0038FU-0048FU+4948GI-0047FU+4837GI-0036FU+5847OU-3637TO\\n+4737OU-0036FU+3747OU-0029GI+0049KE-0027GI+4758OU-0047FU+5747KI-6667TO+6867KY-0078KI+6959KI-0048FU+4748KI-7879KI+5968KI-0047FU+4847KI\\n-7787RY+4748KI-7978KI+0069FU-7868KI%TORYO\\nTableS7:10gamesplayedbyAlphaZeroagainstElmo,selectedbyYoshiharuHabu.\\n31\\n', 'AlphaZero\\nOpponent\\nFig.MatchStartPosition\\nBookMainInc\\nBookMainIncProgram\\n2AMainInitialBoard\\nNo3h15s\\nNo3h15s8\\n2B1/100timeInitialBoard\\nNo108s0.15s\\nNo3h15s8\\n2B1/30timeInitialBoard\\nNo6min0.5s\\nNo3h15s8\\n2B1/10timeInitialBoard\\nNo18min1.5s\\nNo3h15s8\\n2B1/3timeInitialBoard\\nNo1h5s\\nNo3h15s8\\n2ClatestInitialBoard\\nNo3h15s\\nNo3h15s2018.01.13\\n2COpeningBookInitialBoard\\nNo3h15s\\nYes3h15s8\\n2DHumanOpeningsFigure3A\\nNo3h15s\\nNo3h15s8\\n2DTCECOpeningsFigureS4\\nNo3h15s\\nNo3h15s8\\nTableS8:Detailedconditionsforthedifferentevaluationsinchess.\\nAlphaZero\\nOpponent\\nFig.MatchStartPosition\\nBookMainInc\\nBookMainIncProgram\\n2AMainInitialBoard\\nNo3h15s\\nYes3h15sElmo\\n2B1/100timeInitialBoard\\nNo108s0.15s\\nYes3h15sElmo\\n2B1/30timeInitialBoard\\nNo6min0.5s\\nYes3h15sElmo\\n2B1/10timeInitialBoard\\nNo18min1.5s\\nYes3h15sElmo\\n2B1/3timeInitialBoard\\nNo1h5s\\nYes3h15sElmo\\n2CAperyqhapaqInitialBoard\\nNo3h15s\\nNo3h15sAperyqhapaq\\n2CCSAtimecontrolInitialBoard\\nNo10min10s\\nYes10min10sElmo\\n2DHumanOpeningsFigure3B\\nNo3h15s\\nYes3h15sElmo\\nTableS9:Detailedconditionsforthedifferentevaluationsinshogi.\\n32\\n']\n"
     ]
    }
   ],
   "source": [
    "# creating an object \n",
    "file = open('alphazero_preprint.pdf', 'rb')\n",
    "\n",
    "# creating a pdf reader object\n",
    "fileReader = PyPDF2.PdfFileReader(file)\n",
    "\n",
    "text = []\n",
    "# print the number of pages in pdf file\n",
    "for i in range(fileReader.numPages):\n",
    "    p = fileReader.getPage(i)\n",
    "    text.append(p.extractText())\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'March 22nd, 2017  RE: Software Developer Job Posting   To Dr. Christopher Collins,   I am writing to you to express my great interest in becoming a part of your team as a software developer position for the Open Social Sciences and Humanities Project. Web is a passion of mine, and having thoroughly enjoyed your Human Computer Interaction course in 2013, I believe this opportunity to work together would be of mutual value.  For the past two years, I have been working with a small team of developers on both frontend and backend development of an ecosystem of web-based applications ranging in use for mobile \\xe2\\x80\\x9con-the-job\\xe2\\x80\\x9d users, custom data analytics reporting, and full enterprise solutions. I believe I would be an effective asset for this project.  I take as much initiative as possible towards personal and professional development, and I try to focus this knowledge into avenues I see relevant. I encourage you to check out my online portfolio which can be found at  in order to see some samples of my work.  I would love for us to meet in order to discuss my qualifications in further detail. Feel free to contact me by e-mail () or mobile (647-774-5769) so we could arrange a place and time.    Thank you in advance, Victor Sawal'\n"
     ]
    }
   ],
   "source": [
    "with open('Cover Letter.docx', 'rb+') as f:\n",
    "    bf = io.BytesIO(f.read())\n",
    "    doc = docx.Document(bf)\n",
    "    text = []\n",
    "    # print the number of pages in pdf file\n",
    "    for p in doc.paragraphs:\n",
    "        text.append(p.text)\n",
    "    print(\" \".join(text).encode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.read_sql(\"select * from word limit 100\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = pd.read_sql(\"select * from tfidf\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
